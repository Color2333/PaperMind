# PaperMind - AI 研究工作流平台

**版本:** 2.1  
**日期:** 2026-02-17  
**作者:** Bamzc  
**核心愿景:** 从"搜索论文"进化为"理解领域"。通过自动化 Agent 和 LLM，将海量文献转化为结构化的知识图谱，辅助研究者完成从"每日追踪"到"深度调研"的全过程。

---

## 1. 用户画像

| 角色 | 描述 | 核心需求 |
|------|------|---------|
| **领域探索者** | 对某个细分领域不熟悉 | 快速理清发展脉络、经典必读论文和最新动态 |
| **资深研究员** | 清楚自己关注什么 | 每日自动化筛选最新论文，过滤噪音，看精读报告 |
| **细节挖掘者** | 需要查找公式、代码细节 | 阅读 PDF 时快速查找、寻找相似技术方案 |

---

## 2. 功能模块与实现状态

### 模块 A: 数据获取与自动化 ✅ 已实现

| 功能 | 状态 | 说明 |
|------|------|------|
| ArXiv API 抓取 | ✅ | 支持关键词搜索、批量入库、429重试与指数退避 |
| Semantic Scholar 集成 | ✅ | 引用数据同步、批量元数据获取 |
| 智能调度 | ✅ | **按主题独立调度**，每小时检查，支持日/两次/工作日/周频率 |
| PDF 自动下载 | ✅ | 入库时自动下载至 data/papers/ |
| 增量更新 | ✅ | SourceCheckpoint 记录上次抓取进度 |
| 主题订阅 | ✅ | 支持自定义频率、执行时间（北京时间）、AI 关键词建议 |
| 并行处理 | ✅ | 论文间并发（3篇同时）+ 单篇内 embed∥skim 并行 |
| 论文筛选流程 | ✅ | Agent 搜索后展示候选列表，用户筛选后才入库 |

### 模块 B: AI 阅读引擎 ✅ 已实现

| 功能 | 状态 | 说明 |
|------|------|------|
| 粗读 (Skim) | ✅ | 标题+摘要 → 一句话总结、创新点、相关度评分、关键词提取、中文翻译 |
| 精读 (Deep Dive) | ✅ | PDF 全文 + Vision 模型 → 方法论、实验、消融、审稿风险 |
| 向量嵌入 | ✅ | 摘要+结论 Embedding，支持语义检索 |
| 成本控制 | ✅ | CostGuard 按预算自动降级模型 |
| LLM 多 Provider | ✅ | OpenAI / Anthropic / 智谱，数据库动态配置，30s TTL 缓存 |

### 模块 C: 知识图谱与脉络 ✅ 已实现

| 功能 | 状态 | 说明 |
|------|------|------|
| 引用树构建 | ✅ | BFS 追溯祖先/后代 |
| 领域时间线 | ✅ | 按关键词 + PageRank + seminal_score |
| 演化分析 | ✅ | 按年聚合 + LLM 趋势总结 |
| 综述生成 | ✅ | overview / stages / reading_list / open_questions |
| Topic Wiki | ✅ | 大纲 → 逐章节生成 → 概述汇总，Canvas 侧面板展示 |
| Paper Wiki | ✅ | 单篇论文百科生成 |

### 模块 D: 向量记忆与问答 ✅ 已实现

| 功能 | 状态 | 说明 |
|------|------|------|
| 向量化存储 | ✅ | SQLite 内嵌 embedding，Paper 表直接存储 |
| 语义相似推荐 | ✅ | 基于 embedding 余弦距离 Top-K，候选池限制 500 |
| 跨文档 RAG 问答 | ✅ | 全文检索 + 向量检索 → LLM 综合回答 |
| RAG 报告持久化 | ✅ | 生成 Artifact 卡片并存入 GeneratedContent |

### 模块 E: AI Agent 对话系统 ✅ 已实现

| 功能 | 状态 | 说明 |
|------|------|------|
| SSE 流式对话 | ✅ | 实时文本流 + 工具调用进度 |
| 工具调用链 | ✅ | 搜索/入库/粗读/嵌入/RAG/Wiki/简报/订阅管理/AI关键词建议 |
| 用户确认机制 | ✅ | 写操作需用户确认后执行 |
| 实时进度条 | ✅ | 工具执行过程流式进度反馈 |
| 会话持久化 | ✅ | localStorage 存储，跨页面状态保持 |
| 自动生成标题 | ✅ | 首次对话自动生成会话标题 |
| 能力标签 | ✅ | 输入框前置能力选择 |
| AI 关键词建议 | ✅ | 自然语言描述 → LLM 生成 arXiv 搜索关键词 |

### 模块 F: 个性化推荐与趋势 ✅ 已实现

| 功能 | 状态 | 说明 |
|------|------|------|
| 用户兴趣画像 | ✅ | 基于已读论文 embedding 聚类中心 |
| 个性化推荐 | ✅ | 未读论文按余弦相似度排序推荐 |
| 热点关键词 | ✅ | 近期论文关键词频率分析 |
| 趋势检测 | ✅ | 两周期对比检测新兴方向 |
| 今日研究速览 | ✅ | Agent 着陆页展示推荐、热点、统计 |

### 模块 G: 前端界面 ✅ 已实现

| 页面 | 功能 |
|------|------|
| Agent（主页） | AI 对话，Manus 风格工具调用 UI，今日研究速览 |
| Papers | 论文列表，主题/关键词/状态筛选，批量粗读/嵌入 |
| Paper Detail | 详情 + 粗读/精读/嵌入/相似论文，含中文翻译 |
| Wiki | 主题/论文 Wiki 生成，Canvas 侧面板 |
| Daily Brief | 每日简报生成与历史 |
| Collect | 论文收集 + 主题订阅管理（频率/时间/AI关键词建议） |
| Graph Explorer | 引用图谱、时间线、演化分析 |
| Dashboard | 系统看板 |
| Settings | LLM 配置统一管理 |

### 技术栈

| 层 | 技术 |
|----|------|
| 前端 | React 18 + Vite + TypeScript + Tailwind CSS v4 |
| 后端 | FastAPI + SQLAlchemy + SQLite (WAL) |
| LLM | OpenAI / Anthropic / 智谱 (GLM-4.6V + GLM-4.7) |
| 调度 | APScheduler（按主题独立调度） |
| 外部 API | ArXiv API, Semantic Scholar API |

### 性能优化（v2.1）

| 领域 | 优化项 |
|------|--------|
| 前端 | 路由懒加载（React.lazy + Suspense），首屏只加载 Agent 页 |
| 前端 | Vite manualChunks 分割 react-vendor / markdown / icons |
| 前端 | AgentSessionContext value useMemo 防止不必要的全局重渲染 |
| 前端 | Papers 列表 filtered useMemo + 回调 useCallback |
| 前端 | Sidebar groupByDate useMemo |
| 后端 | LLM 配置 30s TTL 缓存，避免每次调用查库 |
| 后端 | OpenAI 客户端连接复用（按 key+url 缓存），设置 120s timeout |
| 后端 | SQLite PRAGMA synchronous=NORMAL + cache_size=64MB + temp_store=MEMORY |
| 后端 | 关键列索引：papers.created_at, prompt_traces.created_at, pipeline_runs.created_at, papers.read_status |
| 后端 | 向量检索候选池限制 500 条，避免全表加载 |

---

## 3. 下阶段优化蓝图

### Phase 5: 多模态深度理解（第一梯队）

#### 5.1 图表/公式智能识别

- **目标**：从 PDF 中自动提取 Figure/Table/公式，逐个送 Vision 模型解读
- **产出**：图表说明卡片、LaTeX 公式还原、架构图模块化描述
- **实现路径**：
  - `pipelines.py` 的 `deep_dive` 增加图表检测步骤
  - 用 PyMuPDF 提取图片区域坐标，截取后送 GLM-4.6V
  - 新增 `ImageAnalysis` 数据模型存储图表解读结果
  - 前端 PaperDetail 增加"图表解读"标签页

#### 5.2 推理链深度分析 (Reasoning Chain)

- **目标**：引入类 o1/DeepSeek-R1 的分步推理，提升论文分析深度
- **产出**：方法论推导链、实验结果验证链、创新性多维评估
- **实现路径**：
  - `prompts.py` 新增 `build_reasoning_prompt()`
  - 用 `<thinking>` 标签引导 LLM 分步推理
  - 推理过程以折叠面板形式展示在前端

#### 5.3 研究空白识别 (Research Gap Detection)

- **目标**：分析引用网络的稀疏区域，发现未被充分探索的研究方向
- **产出**：跨论文方法对比矩阵、引用稀疏方向检测、研究建议报告
- **实现路径**：
  - `graph_service.py` 新增 `detect_research_gaps()`
  - 结合引用网络拓扑分析 + LLM 推理
  - Agent 工具链增加 `identify_research_gaps` 工具

---

### Phase 6: 知识增强检索（第二梯队）

#### 6.1 GraphRAG（图谱增强检索）— 渐进式改进

- **目标**：在现有 RAG 基础上渐进融入图谱结构信息，提升宏观问题回答质量
- **策略**：不另起炉灶，在 `rag_service.py` 上迭代演进，新旧检索能力并存
- **产出**：论文社区检测与社区摘要、分层检索（社区→论文→片段）
- **实现路径**：
  - 在现有 `rag_service.py` 中增加图谱上下文注入
  - 用 `networkx` Louvain 算法做社区检测，结果缓存
  - 查询时先匹配社区摘要，再在社区内精搜，与现有向量检索结果合并
  - 渐进式切换：A/B 模式，用户可选择是否启用图谱增强

#### 6.2 多智能体协作系统 — 效果优先

- **目标**：在效果可验证的前提下，将单 Agent 拆分为多个专业 Agent
- **原则**：不为拆而拆，先验证多 Agent 在特定场景（如综述生成）中的效果提升，再逐步扩展
- **角色设计**：

  | Agent | 职责 | 工具权限 |
  |-------|------|---------|
  | 搜索员 | 查找和筛选论文 | search, arXiv ingest |
  | 分析师 | 深度阅读和评审 | skim, deep_read, RAG |
  | 写作者 | 生成 Wiki、简报、综述 | generate_wiki, brief |
  | 审稿人 | 质量把关与反馈 | 只读 + 反馈 |

- **实现路径**：
  - 先在综述生成场景试点：写作者 + 审稿人 双 Agent 迭代
  - 验证效果后再扩展到完整的 Orchestrator 模式
  - 保留单 Agent 作为默认模式，多 Agent 作为高级选项

#### 6.3 自动化学术综述生成

- **目标**：生成接近发表质量的学术综述文档
- **产出**：多轮迭代写作（大纲→初稿→审核→修改→终稿）、自动引用标注、LaTeX/Word 导出
- **实现路径**：
  - 新建 `packages/ai/survey_writer.py`
  - 多轮 LLM 调用 + 自我审核循环
  - 自动插入 `[Author, Year]` 格式引用
  - 用 `python-docx` 或 `pylatex` 导出

#### 6.4 论文代码关联与复现辅助

- **目标**：自动关联论文的开源实现，辅助实验复现
- **产出**：GitHub 仓库关联、伪代码提取、复现步骤指南
- **实现路径**：
  - 集成 Papers with Code API
  - `agent_tools.py` 新增 `find_code_repo` 工具
  - 精读流程增加代码块检测步骤

---

### Phase 7: 体验打磨与智能推送（第三梯队）

#### 7.1 智能论文监控与推送

- **目标**：基于语义（非关键词）的智能论文发现与推送
- **产出**：
  - 语义订阅：跟已读论文向量相似的新论文自动推送
  - 突破性论文检测：引用量急增、被多社区引用的论文自动标记
  - 多渠道推送：邮件 + 飞书/Telegram
- **实现路径**：
  - 推荐引擎 + 每日 arXiv 扫描
  - 异常检测算法标记热门论文
  - 集成飞书/Telegram Webhook

#### 7.2 Agent 交互体验深度优化

- **目标**：打磨单人使用体验至极致
- **产出**：
  - 对话记忆增强：跨会话记住用户的研究偏好和历史结论
  - 主动提醒：基于订阅主题有新进展时主动推送
  - 快捷操作：支持更多自然语言快捷指令
- **实现路径**：
  - 用户画像持久化存储
  - 定时任务检测新论文与用户画像匹配度
  - Agent system prompt 动态注入用户偏好上下文

---

## 4. 实施路线图总览

```
已完成 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Phase 1: 基础设施与每日追踪         ✅ ArXiv 抓取、粗读、HTML 日报
Phase 2: 深度阅读与 RAG            ✅ PDF 精读、向量化、RAG 问答
Phase 3: 知识图谱与脉络            ✅ 引用树、时间线、Wiki 生成
Phase 4: AI Agent + 前端重构       ✅ SSE 流式对话、工具链、Claude 风格 UI
Phase 4.5: 个性化推荐 + 调度增强   ✅ 推荐引擎、热点趋势、按主题独立调度、AI 关键词
Phase 4.6: 性能优化                ✅ 路由懒加载、LLM 客户端复用、SQLite 调优、索引

下阶段 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Phase 5: 多模态深度理解（1-2周）
  → 图表/公式识别 + 推理链 + 研究空白识别

Phase 6: 知识增强检索（2-3周）
  → GraphRAG + 多智能体协作 + 自动综述 + 代码关联

Phase 7: 体验打磨与智能推送（远期）
  → 智能论文监控推送 + Agent 交互体验深度优化
```

---

## 5. 已确认决策

| # | 问题 | 决策 |
|---|------|------|
| 1 | 多智能体 vs 单 Agent 增强 | 可以做多 Agent，但效果优先，先试点再扩展 |
| 2 | GraphRAG 社区粒度 | 在现有 RAG 基础上渐进改进，新旧并存 |
| 3 | 本地模型部署 | ❌ 不做，无 GPU 资源 |
| 4 | 协作需求 | ❌ 不做，专注单人体验优化 |
| 5 | MCP 生态 | ❌ 不做，当前无实际需求 |
| 6 | 开发优先级 | 基础体验优化 > 高级特性，功能完美度 > 功能数量 |
| 7 | 定时调度模型 | 按主题独立调度（每小时 dispatch），弃用全局单一 cron |
| 8 | AI 关键词建议 | 同时支持 /collect 页面和 Agent 对话 |
