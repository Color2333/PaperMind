#!/usr/bin/env python3
"""
å®šæœŸæ¸…ç†æœªè¯»è®ºæ–‡ - æ‰¹é‡ç²—è¯» + åµŒå…¥ï¼ˆä¸ç²¾è¯»ï¼‰
@author Color2333

ä½¿ç”¨æ–¹å¼:
    # å¤„ç† 20 ç¯‡ï¼ˆé»˜è®¤ï¼‰
    python scripts/cleanup_unread.py

    # å¤„ç† 50 ç¯‡ï¼Œå¹¶å‘ 5 ä¸ª
    python scripts/cleanup_unread.py --limit 50 --concurrency 5

    # æ·»åŠ åˆ° crontabï¼ˆæ¯å¤© UTC 14 ç‚¹æ‰§è¡Œï¼ŒåŒ—äº¬æ—¶é—´ 22 ç‚¹ï¼‰
    0 14 * * * cd /path/to/PaperMind && /path/to/venv/bin/python scripts/cleanup_unread.py --limit 30
"""

from __future__ import annotations

import argparse
import logging
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timezone
from pathlib import Path

from packages.ai.pipelines import PaperPipelines
from packages.ai.rate_limiter import acquire_api, get_rate_limiter
from packages.config import get_settings
from packages.storage.db import session_scope
from packages.storage.models import Paper, AnalysisReport
from sqlalchemy import select

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


def get_unread_papers(limit: int = 50) -> list[tuple[str, str, str]]:
    """
    è·å–æœªè¯»ä¸”æœªå¤„ç†çš„è®ºæ–‡åˆ—è¡¨

    Returns:
        list: [(paper_id, title, arxiv_id), ...]
    """
    with session_scope() as session:
        # æŸ¥è¯¢æœªè¯»è®ºæ–‡ï¼Œå·¦è¿æ¥åˆ†æè¡¨ï¼Œç­›é€‰æ²¡æœ‰åˆ†æçš„
        papers = session.execute(
            select(Paper.id, Paper.title, Paper.arxiv_id)
            .where(Paper.read_status == "unread")
            .outerjoin(AnalysisReport, Paper.id == AnalysisReport.paper_id)
            .where((AnalysisReport.summary_md.is_(None)) | (AnalysisReport.id.is_(None)))
            .order_by(Paper.created_at.asc())  # ä¼˜å…ˆå¤„ç†æ—§çš„
            .limit(limit)
        ).all()
        return [(str(p.id), p.title, p.arxiv_id) for p in papers]


def process_single_paper(paper_id: str, title: str, arxiv_id: str) -> dict:
    """
    å¤„ç†å•ç¯‡è®ºæ–‡ï¼šåªç²—è¯» + åµŒå…¥ï¼Œä¸ç²¾è¯»

    Returns:
        dict: å¤„ç†ç»“æœ
    """
    pipelines = PaperPipelines()
    result = {
        "paper_id": paper_id[:8],
        "title": title[:50],
        "arxiv_id": arxiv_id,
        "skim_success": False,
        "embed_success": False,
        "skim_score": None,
        "error": None,
    }

    try:
        # Step 1: åµŒå…¥
        logger.info(f"ğŸ“Œ [{paper_id[:8]}] å¼€å§‹åµŒå…¥...")
        try:
            if acquire_api("embedding", timeout=30.0):
                pipelines.embed_paper(paper_id)
                result["embed_success"] = True
                logger.info(f"âœ… [{paper_id[:8]}] åµŒå…¥å®Œæˆ")
            else:
                result["error"] = "Embedding API é™æµ"
                logger.warning(f"âš ï¸  [{paper_id[:8]}] Embedding API é™æµï¼Œè·³è¿‡")
        except Exception as e:
            result["error"] = f"embed: {e}"
            logger.warning(f"âŒ [{paper_id[:8]}] åµŒå…¥å¤±è´¥ï¼š{e}")

        # Step 2: ç²—è¯»
        logger.info(f"ğŸ“– [{paper_id[:8]}] å¼€å§‹ç²—è¯»...")
        try:
            if acquire_api("llm", timeout=30.0):
                skim_result = pipelines.skim(paper_id)
                result["skim_success"] = True
                if skim_result and skim_result.relevance_score:
                    result["skim_score"] = skim_result.relevance_score
                    logger.info(
                        f"âœ… [{paper_id[:8]}] ç²—è¯»å®Œæˆ (åˆ†æ•°={skim_result.relevance_score:.2f})"
                    )
                else:
                    logger.info(f"âœ… [{paper_id[:8]}] ç²—è¯»å®Œæˆ (åˆ†æ•°=N/A)")
            else:
                result["error"] = "LLM API é™æµ"
                logger.warning(f"âš ï¸  [{paper_id[:8]}] LLM API é™æµï¼Œè·³è¿‡ç²—è¯»")
        except Exception as e:
            result["error"] = f"skim: {e}"
            logger.warning(f"âŒ [{paper_id[:8]}] ç²—è¯»å¤±è´¥ï¼š{e}")

    except Exception as e:
        result["error"] = str(e)
        logger.exception(f"âŒ [{paper_id[:8]}] å¤„ç†å¼‚å¸¸ï¼š{e}")

    return result


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡ - åªç²—è¯» + åµŒå…¥ï¼Œä¸ç²¾è¯»",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¤„ç† 20 ç¯‡ï¼ˆé»˜è®¤ï¼‰
  python scripts/cleanup_unread.py
  
  # å¤„ç† 50 ç¯‡ï¼Œå¹¶å‘ 5 ä¸ª
  python scripts/cleanup_unread.py --limit 50 --concurrency 5
  
  # æ·»åŠ åˆ° crontabï¼ˆæ¯å¤© UTC 14 ç‚¹æ‰§è¡Œï¼‰
  0 14 * * * cd /path/to/PaperMind && /path/to/venv/bin/python scripts/cleanup_unread.py --limit 30
        """,
    )
    parser.add_argument("--limit", type=int, default=20, help="æ¯æ¬¡å¤„ç†çš„è®ºæ–‡æ•°é‡ (é»˜è®¤ 20)")
    parser.add_argument(
        "--concurrency", type=int, default=3, help="å¹¶å‘å¤„ç†æ•°é‡ (é»˜è®¤ 3ï¼Œé¿å… LLM é™æµ)"
    )
    parser.add_argument("--dry-run", action="store_true", help="åªæ˜¾ç¤ºå¾…å¤„ç†è®ºæ–‡ï¼Œä¸æ‰§è¡Œå¤„ç†")
    args = parser.parse_args()

    print("=" * 70)
    print("ğŸš€ PaperMind æœªè¯»è®ºæ–‡æ‰¹é‡å¤„ç†å™¨")
    print("=" * 70)
    print()

    # è·å–å¾…å¤„ç†è®ºæ–‡
    papers = get_unread_papers(limit=args.limit)

    if not papers:
        print("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„æœªè¯»è®ºæ–‡ï¼")
        print()
        print("æ‰€æœ‰æœªè¯»è®ºæ–‡éƒ½å·²ç»å®Œæˆç²—è¯»å’ŒåµŒå…¥å¤„ç†ã€‚")
        return

    print(f"ğŸ“Š æ‰¾åˆ° {len(papers)} ç¯‡å¾…å¤„ç†è®ºæ–‡")
    print(f"âš¡ å¹¶å‘æ•°ï¼š{args.concurrency}")
    print(f"ğŸ“‹ å¤„ç†æ¨¡å¼ï¼šç²—è¯» + åµŒå…¥ (ä¸ç²¾è¯»)")
    print()

    if args.dry_run:
        print("ğŸ” å¾…å¤„ç†è®ºæ–‡åˆ—è¡¨:")
        for i, (pid, title, arxiv_id) in enumerate(papers, 1):
            print(f"  {i:2d}. {title[:60]}")
            print(f"      ID: {pid[:8]}... | arXiv: {arxiv_id}")
        print()
        print("ï¼ˆä½¿ç”¨ --dry-run é¢„è§ˆï¼Œç§»é™¤è¯¥å‚æ•°å¼€å§‹å¤„ç†ï¼‰")
        return

    # æ‰¹é‡å¤„ç†
    results = []
    start_time = datetime.now(timezone.utc)

    limiter = get_rate_limiter()

    with ThreadPoolExecutor(max_workers=args.concurrency) as executor:
        futures = {
            executor.submit(process_single_paper, pid, title, arxiv_id): pid
            for pid, title, arxiv_id in papers
        }

        for i, future in enumerate(as_completed(futures), 1):
            result = future.result()
            results.append(result)

            # è¿›åº¦æ±‡æŠ¥
            if i % 5 == 0 or i == len(papers):
                success = sum(1 for r in results if r["skim_success"] and r["embed_success"])
                partial = sum(1 for r in results if r["skim_success"] or r["embed_success"])
                errors = sum(1 for r in results if r["error"])

                elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()
                eta = (elapsed / i * (len(papers) - i)) if i > 0 else 0

                logger.info(
                    f"è¿›åº¦ï¼š{i}/{len(papers)} | "
                    f"æˆåŠŸï¼š{success} | éƒ¨åˆ†ï¼š{partial} | å¤±è´¥ï¼š{errors} | "
                    f"é¢„è®¡å‰©ä½™ï¼š{eta:.0f}s"
                )

    # ç»Ÿè®¡ç»“æœ
    print()
    print("=" * 70)
    print("ğŸ“‹ å¤„ç†ç»“æœç»Ÿè®¡")
    print("=" * 70)

    total = len(results)
    embed_ok = sum(1 for r in results if r["embed_success"])
    skim_ok = sum(1 for r in results if r["skim_success"])
    both_ok = sum(1 for r in results if r["skim_success"] and r["embed_success"])
    errors = sum(1 for r in results if r["error"])

    elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()

    print(f"æ€»å¤„ç†ï¼š{total} ç¯‡")
    print(f"âœ… åµŒå…¥æˆåŠŸï¼š{embed_ok} ({embed_ok / total * 100:.1f}%)")
    print(f"âœ… ç²—è¯»æˆåŠŸï¼š{skim_ok} ({skim_ok / total * 100:.1f}%)")
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼š{both_ok} ({both_ok / total * 100:.1f}%)")
    print(f"âŒ å‡ºç°é”™è¯¯ï¼š{errors} ({errors / total * 100:.1f}%)")
    print(f"â±ï¸  æ€»è€—æ—¶ï¼š{elapsed:.1f}ç§’")
    print(f"âš¡ å¹³å‡é€Ÿåº¦ï¼š{elapsed / total:.1f}ç§’/ç¯‡")
    print()

    # æ˜¾ç¤ºå¤±è´¥çš„
    if errors > 0:
        print("âš ï¸  ä»¥ä¸‹è®ºæ–‡å¤„ç†å¤±è´¥:")
        for r in results:
            if r["error"]:
                print(f"  - {r['title'][:40]}... : {r['error']}")
        print()

    # é«˜åˆ†è®ºæ–‡æç¤º
    high_score_papers = [
        r for r in results if r["skim_success"] and r["skim_score"] and r["skim_score"] >= 0.8
    ]
    if high_score_papers:
        print("ğŸ¯ å‘ç°é«˜åˆ†è®ºæ–‡ï¼ˆå»ºè®®ç²¾è¯»ï¼‰:")
        for r in high_score_papers:
            print(f"  - {r['title'][:40]}... (åˆ†æ•°={r['skim_score']:.2f})")
        print()

    print("âœ¨ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print()
    print("ğŸ’¡ æç¤º:")
    print("  â€¢ å¯ä»¥åœ¨å‰ç«¯æ‰‹åŠ¨è§¦å‘é«˜åˆ†è®ºæ–‡çš„ç²¾è¯»")
    print("  â€¢ æˆ–æ·»åŠ å®šæ—¶ä»»åŠ¡å®šæœŸæ‰§è¡Œæ­¤è„šæœ¬")
    print("  â€¢ æ¨èé…ç½®ï¼šæ¯å¤© UTC 14 ç‚¹å¤„ç† 30 ç¯‡")
    print()


if __name__ == "__main__":
    main()
