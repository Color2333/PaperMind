"""
é—²æ—¶è‡ªåŠ¨å¤„ç†å™¨ - æ£€æµ‹ç³»ç»Ÿç©ºé—²çŠ¶æ€ï¼Œè‡ªåŠ¨æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡
@author Color2333
"""

from __future__ import annotations

import logging
import os
import time
from datetime import datetime, timezone
from threading import Thread, Event
from typing import Optional, Callable

from packages.ai.pipelines import PaperPipelines
from packages.ai.rate_limiter import get_rate_limiter, acquire_api
from packages.config import get_settings
from packages.storage.db import session_scope
from packages.storage.models import Paper, AnalysisReport
from packages.storage.repositories import PaperRepository
from sqlalchemy import select

logger = logging.getLogger(__name__)


class IdleDetector:
    """
    ç³»ç»Ÿç©ºé—²çŠ¶æ€æ£€æµ‹å™¨

    æ£€æµ‹æŒ‡æ ‡ï¼š
    - CPU ä½¿ç”¨ç‡ < 30%
    - å†…å­˜ä½¿ç”¨ç‡ < 70%
    - æ— æ´»è·ƒç”¨æˆ·è¯·æ±‚ï¼ˆAPI è¯·æ±‚æ•° < 5/åˆ†é’Ÿï¼‰
    - è·ç¦»ä¸Šæ¬¡ä»»åŠ¡æ‰§è¡Œ > 10 åˆ†é’Ÿ
    """

    def __init__(
        self,
        cpu_threshold: float = 30.0,
        memory_threshold: float = 70.0,
        request_threshold: int = 5,
        idle_interval: int = 600,
    ):
        self.cpu_threshold = cpu_threshold
        self.memory_threshold = memory_threshold
        self.request_threshold = request_threshold
        self.idle_interval = idle_interval  # ç§’

        self._last_task_time = 0
        self._request_count = 0
        self._request_window = 60  # 1 åˆ†é’Ÿçª—å£
        self._request_timestamps = []

    def record_request(self):
        """è®°å½•ä¸€æ¬¡ API è¯·æ±‚"""
        now = time.time()
        self._request_timestamps.append(now)

        # æ¸…ç†è¿‡æœŸè®°å½•
        cutoff = now - self._request_window
        self._request_timestamps = [ts for ts in self._request_timestamps if ts > cutoff]

    def _get_cpu_usage(self) -> float:
        """è·å– CPU ä½¿ç”¨ç‡"""
        try:
            # å°è¯•ä½¿ç”¨ psutil
            import psutil

            return psutil.cpu_percent(interval=0.1)
        except ImportError:
            # æ²¡æœ‰ psutilï¼Œè¿”å›ä¿å®ˆä¼°è®¡å€¼
            logger.debug("psutil æœªå®‰è£…ï¼Œä½¿ç”¨ä¿å®ˆ CPU ä¼°è®¡")
            return 50.0

    def _get_memory_usage(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨ç‡"""
        try:
            import psutil

            return psutil.virtual_memory().percent
        except ImportError:
            logger.debug("psutil æœªå®‰è£…ï¼Œä½¿ç”¨ä¿å®ˆå†…å­˜ä¼°è®¡")
            return 50.0

    def _get_recent_request_rate(self) -> int:
        """è·å–æœ€è¿‘çš„è¯·æ±‚é€Ÿç‡ï¼ˆè¯·æ±‚æ•°/åˆ†é’Ÿï¼‰"""
        return len(self._request_timestamps)

    def is_idle(self) -> bool:
        """
        åˆ¤æ–­ç³»ç»Ÿæ˜¯å¦å¤„äºç©ºé—²çŠ¶æ€

        Returns:
            bool: æ˜¯å¦ç©ºé—²
        """
        # æ£€æŸ¥è·ç¦»ä¸Šæ¬¡ä»»åŠ¡æ‰§è¡Œçš„æ—¶é—´
        if time.time() - self._last_task_time < self.idle_interval:
            return False

        # æ£€æŸ¥ CPU
        cpu_usage = self._get_cpu_usage()
        if cpu_usage > self.cpu_threshold:
            logger.debug("CPU ä½¿ç”¨ç‡è¿‡é«˜ (%.1f%%)ï¼Œä¸æ»¡è¶³ç©ºé—²æ¡ä»¶", cpu_usage)
            return False

        # æ£€æŸ¥å†…å­˜
        memory_usage = self._get_memory_usage()
        if memory_usage > self.memory_threshold:
            logger.debug("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ (%.1f%%)ï¼Œä¸æ»¡è¶³ç©ºé—²æ¡ä»¶", memory_usage)
            return False

        # æ£€æŸ¥è¯·æ±‚é€Ÿç‡
        request_rate = self._get_recent_request_rate()
        if request_rate > self.request_threshold:
            logger.debug("è¯·æ±‚é€Ÿç‡è¿‡é«˜ (%d/min)ï¼Œä¸æ»¡è¶³ç©ºé—²æ¡ä»¶", request_rate)
            return False

        logger.info(
            "âœ… ç³»ç»Ÿç©ºé—²æ£€æµ‹é€šè¿‡ (CPU=%.1f%%, Mem=%.1f%%, Req=%d/min)",
            cpu_usage,
            memory_usage,
            request_rate,
        )
        return True

    def mark_task_executed(self):
        """æ ‡è®°ä»»åŠ¡å·²æ‰§è¡Œï¼Œé‡ç½®ç©ºé—²è®¡æ—¶å™¨"""
        self._last_task_time = time.time()
        logger.debug("é—²æ—¶ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œé‡ç½®ç©ºé—²è®¡æ—¶å™¨")


class IdleProcessor:
    """
    é—²æ—¶è‡ªåŠ¨å¤„ç†å™¨

    åŠŸèƒ½ï¼š
    - å®šæœŸæ£€æµ‹ç³»ç»Ÿç©ºé—²çŠ¶æ€
    - ç©ºé—²æ—¶è‡ªåŠ¨æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡ï¼ˆåªç²—è¯» + åµŒå…¥ï¼Œä¸ç²¾è¯»ï¼‰
    - é‡åˆ°ç”¨æˆ·è¯·æ±‚ç«‹å³æš‚åœ
    - å¯é…ç½®å¤„ç†æ•°é‡å’Œå¹¶å‘åº¦
    """

    def __init__(
        self,
        idle_detector: Optional[IdleDetector] = None,
        batch_size: int = 5,
        check_interval: int = 60,
    ):
        self.detector = idle_detector or IdleDetector()
        self.batch_size = batch_size
        self.check_interval = check_interval  # ç§’

        self._stop_event = Event()
        self._thread: Optional[Thread] = None
        self._is_processing = False
        self._papers_processed = 0

    def _get_unread_papers(self, limit: int = 10) -> list[tuple[str, str]]:
        """
        è·å–æœªè¯»ä¸”æœªå¤„ç†çš„è®ºæ–‡

        Returns:
            list: [(paper_id, title), ...]
        """
        with session_scope() as session:
            papers = session.execute(
                select(Paper.id, Paper.title)
                .where(Paper.read_status == "unread")
                .outerjoin(AnalysisReport, Paper.id == AnalysisReport.paper_id)
                .where((AnalysisReport.summary_md.is_(None)) | (AnalysisReport.id.is_(None)))
                .order_by(Paper.created_at.asc())  # ä¼˜å…ˆå¤„ç†æ—§çš„
                .limit(limit)
            ).all()
            return [(str(p.id), p.title) for p in papers]

    def _process_batch(self) -> int:
        """
        å¤„ç†ä¸€æ‰¹è®ºæ–‡ï¼ˆå¸¦ä»»åŠ¡è¿½è¸ªï¼‰

        Returns:
            int: å¤„ç†çš„è®ºæ–‡æ•°é‡
        """
        from packages.domain.task_tracker import global_tracker

        papers = self._get_unread_papers(limit=self.batch_size)

        if not papers:
            logger.info("æ²¡æœ‰éœ€è¦å¤„ç†çš„æœªè¯»è®ºæ–‡")
            return 0

        # å¯åŠ¨ä»»åŠ¡è¿½è¸ª
        task_id = f"idle_skim_{int(time.time())}"
        global_tracker.start(
            task_id=task_id,
            task_type="idle_skim",
            title=f"ğŸ¤– é—²æ—¶ç²—è¯» ({len(papers)} ç¯‡)",
            total=len(papers),
        )

        logger.info("ğŸ“ é—²æ—¶å¤„ç†å¼€å§‹ï¼š%d ç¯‡è®ºæ–‡ (å¹¶å‘åº¦=3)", len(papers))

        processed = 0
        failed = 0
        pipelines = PaperPipelines()
        limiter = get_rate_limiter()

        try:
            for i, (paper_id, title) in enumerate(papers):
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æš‚åœ
                if not self.detector.is_idle():
                    logger.warning("ç³»ç»Ÿä¸å†ç©ºé—²ï¼Œæš‚åœå¤„ç†")
                    global_tracker.update(
                        task_id=task_id,
                        current=processed,
                        message="ç³»ç»Ÿç¹å¿™ï¼Œæš‚åœå¤„ç†",
                    )
                    break

                # æ›´æ–°è¿›åº¦
                global_tracker.update(
                    task_id=task_id,
                    current=i + 1,
                    message=f"å¤„ç†ï¼š{title[:50]}...",
                )

                # æ£€æŸ¥å¹¶å‘è®¸å¯
                if not limiter.start_task():
                    logger.debug("å¹¶å‘æ•°å·²è¾¾ä¸Šé™ï¼Œç­‰å¾…...")
                    time.sleep(2)
                    continue

                try:
                    logger.info("å¤„ç†ï¼š%s", title[:50])

                    # è·å– API è®¸å¯
                    if not acquire_api("embedding", timeout=30.0):
                        logger.warning("Embedding API é™æµï¼Œè·³è¿‡")
                        failed += 1
                        continue

                    # åµŒå…¥
                    try:
                        pipelines.embed_paper(str(paper_id))
                        logger.info("âœ… åµŒå…¥å®Œæˆï¼š%s", title[:40])
                    except Exception as e:
                        logger.warning("åµŒå…¥å¤±è´¥ï¼š%s - %s", title[:40], e)
                        failed += 1
                        continue

                    # è·å– API è®¸å¯
                    if not acquire_api("llm", timeout=30.0):
                        logger.warning("LLM API é™æµï¼Œè·³è¿‡ç²—è¯»")
                        continue

                    # ç²—è¯»
                    try:
                        result = pipelines.skim(str(paper_id))
                        score = result.relevance_score if result else None
                        logger.info("âœ… ç²—è¯»å®Œæˆï¼š%s (åˆ†æ•°=%.2f)", title[:40], score or 0)
                    except Exception as e:
                        logger.warning("ç²—è¯»å¤±è´¥ï¼š%s - %s", title[:40], e)
                        failed += 1
                        continue

                    processed += 1

                    # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…è¿‡äºé¢‘ç¹
                    time.sleep(1)

                finally:
                    limiter.end_task()

            global_tracker.finish(task_id, success=True)
            logger.info("ğŸ“Š é—²æ—¶å¤„ç†å®Œæˆï¼šæˆåŠŸ=%d, å¤±è´¥=%d", processed, failed)

        except Exception as exc:
            global_tracker.finish(task_id, success=False, error=str(exc)[:200])
            logger.error("âŒ é—²æ—¶å¤„ç†å¤±è´¥ï¼š%s", exc)

        self._papers_processed += processed
        self.detector.mark_task_executed()

        return processed

    def _run_loop(self):
        """ä¸»å¾ªç¯"""
        logger.info("ğŸ¤– é—²æ—¶å¤„ç†å™¨å¯åŠ¨")

        while not self._stop_event.is_set():
            try:
                # æ£€æŸ¥æ˜¯å¦ç©ºé—²
                if self.detector.is_idle():
                    if not self._is_processing:
                        self._is_processing = True
                        self._process_batch()
                        self._is_processing = False
                else:
                    if self._is_processing:
                        logger.info("æš‚åœå¤„ç†ï¼ˆç³»ç»Ÿç¹å¿™ï¼‰")
                        self._is_processing = False

                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                self._stop_event.wait(self.check_interval)

            except Exception as e:
                logger.exception("é—²æ—¶å¤„ç†å™¨å¼‚å¸¸ï¼š%s", e)
                self._is_processing = False
                time.sleep(10)

        logger.info("é—²æ—¶å¤„ç†å™¨å·²åœæ­¢")

    def start(self):
        """å¯åŠ¨é—²æ—¶å¤„ç†å™¨"""
        if self._thread and self._thread.is_alive():
            logger.warning("é—²æ—¶å¤„ç†å™¨å·²åœ¨è¿è¡Œ")
            return

        self._stop_event.clear()
        self._thread = Thread(target=self._run_loop, daemon=True)
        self._thread.start()
        logger.info("âœ… é—²æ—¶å¤„ç†å™¨å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢é—²æ—¶å¤„ç†å™¨"""
        logger.info("åœæ­¢é—²æ—¶å¤„ç†å™¨...")
        self._stop_event.set()

        if self._thread:
            self._thread.join(timeout=10)

        logger.info("é—²æ—¶å¤„ç†å™¨å·²åœæ­¢")

    def get_status(self) -> dict:
        """è·å–çŠ¶æ€"""
        return {
            "running": self._thread is not None and self._thread.is_alive(),
            "is_processing": self._is_processing,
            "papers_processed": self._papers_processed,
            "batch_size": self.batch_size,
            "check_interval": self.check_interval,
        }


# å…¨å±€å•ä¾‹
_global_processor: Optional[IdleProcessor] = None


def get_idle_processor() -> IdleProcessor:
    """è·å–å…¨å±€é—²æ—¶å¤„ç†å™¨å®ä¾‹"""
    global _global_processor

    if _global_processor is None:
        settings = get_settings()
        _global_processor = IdleProcessor(
            batch_size=getattr(settings, "idle_batch_size", 5),
            check_interval=getattr(settings, "idle_check_interval", 60),
        )

    return _global_processor


def start_idle_processor():
    """å¯åŠ¨é—²æ—¶å¤„ç†å™¨"""
    get_idle_processor().start()


def stop_idle_processor():
    """åœæ­¢é—²æ—¶å¤„ç†å™¨"""
    get_idle_processor().stop()


def record_api_request():
    """è®°å½• API è¯·æ±‚ï¼ˆç”¨äºç©ºé—²æ£€æµ‹ï¼‰"""
    detector = getattr(_global_processor, "detector", None)
    if detector:
        detector.record_request()
