"""å¼•ç”¨å›¾è°± & å¼•ç”¨åŒæ­¥è·¯ç”±
@author Color2333
"""

from uuid import UUID

from fastapi import APIRouter, Query

from apps.api.deps import cache, get_paper_title, graph_service
from packages.domain.task_tracker import global_tracker
from packages.storage.db import session_scope
from packages.storage.repositories import TopicRepository

router = APIRouter()


# ---------- å¼•ç”¨åŒæ­¥ ----------
# æ³¨æ„ï¼šå›ºå®šè·¯å¾„å¿…é¡»åœ¨ {paper_id} åŠ¨æ€è·¯å¾„ä¹‹å‰ï¼Œå¦åˆ™ä¼šè¢«é”™è¯¯åŒ¹é…


@router.post("/citations/sync/incremental")
def sync_citations_incremental(
    paper_limit: int = Query(default=40, ge=1, le=200),
    edge_limit_per_paper: int = Query(default=6, ge=1, le=50),
) -> dict:
    """å¢žé‡åŒæ­¥å¼•ç”¨ï¼ˆåŽå°æ‰§è¡Œï¼‰"""

    def _fn(progress_callback=None):
        return graph_service.sync_incremental(
            paper_limit=paper_limit,
            edge_limit_per_paper=edge_limit_per_paper,
        )

    task_id = global_tracker.submit("citation_sync", "ðŸ“Š å¢žé‡å¼•ç”¨åŒæ­¥", _fn)
    return {"task_id": task_id, "message": "å¢žé‡å¼•ç”¨åŒæ­¥å·²å¯åŠ¨", "status": "running"}


@router.post("/citations/sync/topic/{topic_id}")
def sync_citations_for_topic(
    topic_id: str,
    paper_limit: int = Query(default=30, ge=1, le=200),
    edge_limit_per_paper: int = Query(default=6, ge=1, le=50),
) -> dict:
    """ä¸»é¢˜å¼•ç”¨åŒæ­¥ï¼ˆåŽå°æ‰§è¡Œï¼‰"""
    topic_name = topic_id
    try:
        with session_scope() as session:
            topic = TopicRepository(session).get_by_id(topic_id)
            if topic:
                topic_name = topic.name
    except Exception:
        pass

    def _fn(progress_callback=None):
        return graph_service.sync_citations_for_topic(
            topic_id=topic_id,
            paper_limit=paper_limit,
            edge_limit_per_paper=edge_limit_per_paper,
        )

    task_id = global_tracker.submit("citation_sync", f"ðŸ“Š ä¸»é¢˜å¼•ç”¨åŒæ­¥: {topic_name}", _fn)
    return {"task_id": task_id, "message": f"ä¸»é¢˜å¼•ç”¨åŒæ­¥å·²å¯åŠ¨: {topic_name}", "status": "running"}


@router.post("/citations/sync/{paper_id}")
def sync_citations(
    paper_id: str,
    limit: int = Query(default=8, ge=1, le=50),
) -> dict:
    """å•ç¯‡è®ºæ–‡å¼•ç”¨åŒæ­¥ï¼ˆåŽå°æ‰§è¡Œï¼‰"""
    paper_title = get_paper_title(UUID(paper_id)) or paper_id[:8]

    def _fn(progress_callback=None):
        return graph_service.sync_citations_for_paper(paper_id=paper_id, limit=limit)

    task_id = global_tracker.submit("citation_sync", f"ðŸ“„ å¼•ç”¨åŒæ­¥: {paper_title[:30]}", _fn)
    return {"task_id": task_id, "message": "è®ºæ–‡å¼•ç”¨åŒæ­¥å·²å¯åŠ¨", "status": "running"}


# ---------- å›¾è°± ----------


@router.get("/graph/similarity-map")
def similarity_map(
    topic_id: str | None = None,
    limit: int = Query(default=200, ge=5, le=500),
) -> dict:
    """è®ºæ–‡ç›¸ä¼¼åº¦ 2D æ•£ç‚¹å›¾ï¼ˆUMAP é™ç»´ï¼‰"""
    return graph_service.similarity_map(topic_id=topic_id, limit=limit)


@router.get("/graph/citation-tree/{paper_id}")
def citation_tree(
    paper_id: str,
    depth: int = Query(default=2, ge=1, le=5),
) -> dict:
    return graph_service.citation_tree(root_paper_id=paper_id, depth=depth)


@router.get("/graph/citation-detail/{paper_id}")
def citation_detail(paper_id: str) -> dict:
    """èŽ·å–å•ç¯‡è®ºæ–‡çš„ä¸°å¯Œå¼•ç”¨è¯¦æƒ…ï¼ˆå«å‚è€ƒæ–‡çŒ®å’Œè¢«å¼•åˆ—è¡¨ï¼‰"""
    return graph_service.citation_detail(paper_id=paper_id)


@router.get("/graph/citation-network/topic/{topic_id}")
def topic_citation_network(topic_id: str) -> dict:
    """èŽ·å–ä¸»é¢˜å†…è®ºæ–‡çš„äº’å¼•ç½‘ç»œ"""
    return graph_service.topic_citation_network(topic_id=topic_id)


@router.post("/graph/citation-network/topic/{topic_id}/deep-trace")
def topic_deep_trace(topic_id: str) -> dict:
    """å¯¹ä¸»é¢˜å†…è®ºæ–‡æ‰§è¡Œæ·±åº¦æº¯æºï¼Œæ‹‰å–å¤–éƒ¨å¼•ç”¨å¹¶è¿›è¡Œå…±å¼•åˆ†æž"""
    return graph_service.topic_deep_trace(topic_id=topic_id)


@router.get("/graph/overview")
def graph_overview() -> dict:
    """å…¨åº“å¼•ç”¨æ¦‚è§ˆ â€” èŠ‚ç‚¹ + è¾¹ + PageRank + ç»Ÿè®¡ï¼ˆ60s ç¼“å­˜ï¼‰"""
    cached = cache.get("graph_overview")
    if cached is not None:
        return cached
    result = graph_service.library_overview()
    cache.set("graph_overview", result, ttl=60)
    return result


@router.get("/graph/bridges")
def graph_bridges() -> dict:
    """è·¨ä¸»é¢˜æ¡¥æŽ¥è®ºæ–‡ï¼ˆ60s ç¼“å­˜ï¼‰"""
    cached = cache.get("graph_bridges")
    if cached is not None:
        return cached
    result = graph_service.cross_topic_bridges()
    cache.set("graph_bridges", result, ttl=60)
    return result


@router.get("/graph/frontier")
def graph_frontier(
    days: int = Query(default=90, ge=7, le=365),
) -> dict:
    """ç ”ç©¶å‰æ²¿æ£€æµ‹ï¼ˆ60s ç¼“å­˜ï¼‰"""
    cache_key = f"graph_frontier_{days}"
    cached = cache.get(cache_key)
    if cached is not None:
        return cached
    result = graph_service.research_frontier(days=days)
    cache.set(cache_key, result, ttl=60)
    return result


@router.get("/graph/cocitation-clusters")
def graph_cocitation_clusters(
    min_cocite: int = Query(default=2, ge=1, le=10),
) -> dict:
    """å…±å¼•èšç±»åˆ†æž"""
    return graph_service.cocitation_clusters(min_cocite=min_cocite)


@router.post("/graph/auto-link")
def graph_auto_link(paper_ids: list[str]) -> dict:
    """æ‰‹åŠ¨è§¦å‘å¼•ç”¨è‡ªåŠ¨å…³è”"""
    return graph_service.auto_link_citations(paper_ids)


@router.get("/graph/timeline")
def graph_timeline(
    keyword: str,
    limit: int = Query(default=100, ge=1, le=500),
) -> dict:
    return graph_service.timeline(keyword=keyword, limit=limit)


@router.get("/graph/quality")
def graph_quality(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    return graph_service.quality_metrics(keyword=keyword, limit=limit)


@router.get("/graph/evolution/weekly")
def graph_weekly_evolution(
    keyword: str,
    limit: int = Query(default=160, ge=1, le=500),
) -> dict:
    return graph_service.weekly_evolution(keyword=keyword, limit=limit)


@router.get("/graph/survey")
def graph_survey(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    return graph_service.survey(keyword=keyword, limit=limit)


@router.get("/graph/research-gaps")
def graph_research_gaps(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    return graph_service.detect_research_gaps(keyword=keyword, limit=limit)
