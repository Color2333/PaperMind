"""å®šæ—¶ä»»åŠ¡ & è¡ŒåŠ¨è®°å½•è·¯ç”±
@author Color2333
"""

import logging
import uuid as _uuid

from fastapi import APIRouter, BackgroundTasks, HTTPException, Query

from apps.api.deps import pipelines
from packages.ai.daily_runner import run_daily_brief, run_daily_ingest, run_weekly_graph_maintenance
from packages.domain.enums import ReadStatus
from packages.domain.task_tracker import global_tracker
from packages.storage.db import session_scope
from packages.storage.repositories import PaperRepository

logger = logging.getLogger(__name__)

router = APIRouter()


@router.post("/jobs/daily/run-once")
def run_daily_once() -> dict:
    """æ¯æ—¥ä»»åŠ¡ï¼ˆæŠ“å–+ç®€æŠ¥ï¼‰- åå°æ‰§è¡Œ"""

    def _fn(progress_callback=None):
        if progress_callback:
            progress_callback("æ­£åœ¨æ‰§è¡Œè®¢é˜…æ”¶é›†...", 10, 100)
        ingest = run_daily_ingest()
        if progress_callback:
            progress_callback("æ­£åœ¨ç”Ÿæˆæ¯æ—¥ç®€æŠ¥...", 70, 100)
        brief = run_daily_brief()
        return {"ingest": ingest, "brief": brief}

    task_id = global_tracker.submit("daily_job", "ğŸ“… æ¯æ—¥ä»»åŠ¡æ‰§è¡Œ", _fn)
    return {"task_id": task_id, "message": "æ¯æ—¥ä»»åŠ¡å·²å¯åŠ¨", "status": "running"}


@router.post("/jobs/graph/weekly-run-once")
def run_weekly_graph_once() -> dict:
    """æ¯å‘¨å›¾ç»´æŠ¤ä»»åŠ¡ - åå°æ‰§è¡Œ"""

    def _fn(progress_callback=None):
        return run_weekly_graph_maintenance()

    task_id = global_tracker.submit("weekly_maintenance", "ğŸ”„ æ¯å‘¨å›¾ç»´æŠ¤", _fn)
    return {"task_id": task_id, "message": "æ¯å‘¨å›¾ç»´æŠ¤å·²å¯åŠ¨", "status": "running"}


@router.post("/jobs/batch-process-unread")
def batch_process_unread(
    background_tasks: BackgroundTasks,
    max_papers: int = Query(default=50, ge=1, le=200),
) -> dict:
    """æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡ï¼ˆembed + skim å¹¶è¡Œï¼‰- åå°æ‰§è¡Œ"""
    import uuid
    from concurrent.futures import ThreadPoolExecutor, as_completed

    from packages.ai.daily_runner import _process_paper, PAPER_CONCURRENCY

    # å…ˆè·å–éœ€è¦å¤„ç†çš„è®ºæ–‡æ•°é‡
    with session_scope() as session:
        repo = PaperRepository(session)
        unread = repo.list_by_read_status(ReadStatus.unread, limit=max_papers)
        target_ids = []
        for p in unread:
            needs_embed = p.embedding is None
            needs_skim = p.read_status == ReadStatus.unread
            if needs_embed or needs_skim:
                target_ids.append(p.id)

    total = len(target_ids)
    if total == 0:
        return {"processed": 0, "total_unread": 0, "message": "æ²¡æœ‰éœ€è¦å¤„ç†çš„æœªè¯»è®ºæ–‡"}

    task_id = f"batch_unread_{uuid.uuid4().hex[:8]}"

    def _run_batch():
        processed = 0
        failed = 0
        try:
            global_tracker.start(
                task_id, "batch_process", f"ğŸ“š æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡ ({total} ç¯‡)", total=total
            )

            with ThreadPoolExecutor(max_workers=PAPER_CONCURRENCY) as pool:
                futs = {pool.submit(_process_paper, pid): pid for pid in target_ids}
                for fut in as_completed(futs):
                    try:
                        fut.result()
                        processed += 1
                        global_tracker.update(
                            task_id, processed, f"æ­£åœ¨å¤„ç†... ({processed}/{total})", total=total
                        )
                    except Exception as exc:
                        failed += 1
                        logger.warning("batch process %s failed: %s", str(futs[fut])[:8], exc)

            global_tracker.finish(task_id, success=True)
            logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {processed} æˆåŠŸ, {failed} å¤±è´¥")
        except Exception as e:
            global_tracker.finish(task_id, success=False, error=str(e))
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}", exc_info=True)

    background_tasks.add_task(_run_batch)
    return {"task_id": task_id, "message": f"æ‰¹é‡å¤„ç†å·²å¯åŠ¨ ({total} ç¯‡è®ºæ–‡)", "status": "running"}


# ---------- è¡ŒåŠ¨è®°å½• ----------


@router.get("/actions")
def list_actions(
    action_type: str | None = None,
    topic_id: str | None = None,
    limit: int = Query(default=50, ge=1, le=200),
    offset: int = Query(default=0, ge=0),
) -> dict:
    """åˆ—å‡ºè®ºæ–‡å…¥åº“è¡ŒåŠ¨è®°å½•"""
    from packages.storage.repositories import ActionRepository

    with session_scope() as session:
        repo = ActionRepository(session)
        actions, total = repo.list_actions(
            action_type=action_type,
            topic_id=topic_id,
            limit=limit,
            offset=offset,
        )
        return {
            "items": [
                {
                    "id": a.id,
                    "action_type": a.action_type,
                    "title": a.title,
                    "query": a.query,
                    "topic_id": a.topic_id,
                    "paper_count": a.paper_count,
                    "created_at": a.created_at.isoformat() if a.created_at else None,
                }
                for a in actions
            ],
            "total": total,
        }


@router.get("/actions/{action_id}")
def get_action_detail(action_id: str) -> dict:
    """è·å–è¡ŒåŠ¨è¯¦æƒ…"""
    from packages.storage.repositories import ActionRepository

    with session_scope() as session:
        repo = ActionRepository(session)
        action = repo.get_action(action_id)
        if not action:
            raise HTTPException(status_code=404, detail="è¡ŒåŠ¨è®°å½•ä¸å­˜åœ¨")
        return {
            "id": action.id,
            "action_type": action.action_type,
            "title": action.title,
            "query": action.query,
            "topic_id": action.topic_id,
            "paper_count": action.paper_count,
            "created_at": action.created_at.isoformat() if action.created_at else None,
        }


@router.get("/actions/{action_id}/papers")
def get_action_papers(
    action_id: str,
    limit: int = Query(default=200, ge=1, le=500),
) -> dict:
    """è·å–æŸæ¬¡è¡ŒåŠ¨å…³è”çš„è®ºæ–‡åˆ—è¡¨"""
    from packages.storage.repositories import ActionRepository

    with session_scope() as session:
        repo = ActionRepository(session)
        papers = repo.get_papers_by_action(action_id, limit=limit)
        return {
            "action_id": action_id,
            "items": [
                {
                    "id": p.id,
                    "title": p.title,
                    "arxiv_id": p.arxiv_id,
                    "publication_date": p.publication_date.isoformat()
                    if p.publication_date
                    else None,
                    "read_status": p.read_status,
                }
                for p in papers
            ],
        }


# ---------- æ¯æ—¥æŠ¥å‘Šä»»åŠ¡ ----------


@router.post("/jobs/daily-report/run-once")
async def run_daily_report_once(background_tasks: BackgroundTasks):
    """å®Œæ•´å·¥ä½œæµï¼ˆç²¾è¯» + ç”Ÿæˆ + å‘é‚®ä»¶ï¼‰â€” åå°æ‰§è¡Œ"""
    import asyncio
    from packages.ai.auto_read_service import AutoReadService

    def _run_workflow_bg():
        task_id = f"daily_report_{_uuid.uuid4().hex[:8]}"
        global_tracker.start(task_id, "daily_report", "ğŸ“Š æ¯æ—¥æŠ¥å‘Šå·¥ä½œæµ", total=100)

        def _progress(msg: str, cur: int, tot: int):
            global_tracker.update(task_id, cur, msg, total=100)

        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(AutoReadService().run_daily_workflow(_progress))
            if result.get("success"):
                global_tracker.finish(task_id, success=True)
            else:
                global_tracker.finish(task_id, success=False, error=result.get("error", "æœªçŸ¥é”™è¯¯"))
        except Exception as e:
            global_tracker.finish(task_id, success=False, error=str(e))
            logger.error(f"æ¯æ—¥æŠ¥å‘Šå·¥ä½œæµå¤±è´¥: {e}", exc_info=True)

    background_tasks.add_task(_run_workflow_bg)
    return {"message": "æ¯æ—¥æŠ¥å‘Šå·¥ä½œæµå·²å¯åŠ¨", "status": "running"}


@router.post("/jobs/daily-report/send-only")
async def run_daily_report_send_only(
    background_tasks: BackgroundTasks,
    recipient: str | None = Query(default=None, description="æ”¶ä»¶äººé‚®ç®±ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä¸å¡«åˆ™ç”¨é…ç½®"),
):
    """å¿«é€Ÿå‘é€æ¨¡å¼ â€” è·³è¿‡ç²¾è¯»ï¼Œç›´æ¥ç”Ÿæˆç®€æŠ¥å¹¶å‘é‚®ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    from packages.ai.auto_read_service import AutoReadService

    def _run_send_only_bg():
        task_id = f"report_send_{_uuid.uuid4().hex[:8]}"
        global_tracker.start(task_id, "report_send", "ğŸ“§ å¿«é€Ÿå‘é€ç®€æŠ¥", total=100)

        def _progress(msg: str, cur: int, tot: int):
            global_tracker.update(task_id, cur, msg, total=100)

        try:
            recipients = (
                [e.strip() for e in recipient.split(",") if e.strip()] if recipient else None
            )
            result = AutoReadService().send_only(recipients, _progress)
            if result.get("success"):
                global_tracker.finish(task_id, success=True)
            else:
                global_tracker.finish(task_id, success=False, error=result.get("error", "æœªçŸ¥é”™è¯¯"))
        except Exception as e:
            global_tracker.finish(task_id, success=False, error=str(e))
            logger.error(f"å¿«é€Ÿå‘é€å¤±è´¥: {e}", exc_info=True)

    background_tasks.add_task(_run_send_only_bg)
    return {"message": "å¿«é€Ÿå‘é€å·²å¯åŠ¨ï¼ˆè·³è¿‡ç²¾è¯»ï¼‰", "status": "running"}


@router.post("/jobs/daily-report/generate-only")
def run_daily_report_generate_only(
    use_cache: bool = Query(default=False, description="æ˜¯å¦ä½¿ç”¨ç¼“å­˜"),
):
    """ä»…ç”Ÿæˆç®€æŠ¥ HTML â€” ä¸å‘é‚®ä»¶ã€ä¸ç²¾è¯»ï¼ˆåŒæ­¥è¿”å›ï¼‰"""
    from packages.ai.auto_read_service import AutoReadService

    html = AutoReadService().step_generate_html(use_cache=use_cache)
    return {"html": html, "used_cache": use_cache}
