"""
PaperMind API - FastAPI å…¥å£
@author Bamzc
"""
import logging
import time
import uuid as _uuid
from datetime import UTC, datetime
from uuid import UUID

from pathlib import Path
from pydantic import BaseModel

from fastapi import FastAPI, HTTPException, Query, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from starlette.middleware.base import BaseHTTPMiddleware
from packages.domain.exceptions import AppError, NotFoundError
from packages.domain.schemas import (
    ReferenceImportReq, SuggestKeywordsReq, AIExplainReq,
    WritingProcessReq, WritingRefineReq, WritingMultimodalReq,
)
from packages.ai.agent_service import (
    confirm_action,
    reject_action,
    stream_chat,
)
from packages.ai.brief_service import DailyBriefService
from packages.ai.daily_runner import (
    run_daily_brief,
    run_daily_ingest,
    run_weekly_graph_maintenance,
)
from packages.ai.graph_service import GraphService
from packages.ai.pipelines import PaperPipelines
from packages.domain.task_tracker import global_tracker
from packages.ai.rag_service import RAGService
from packages.config import get_settings
from packages.domain.enums import ReadStatus
from packages.domain.schemas import (
    AgentChatRequest,
    AskRequest,
    AskResponse,
    DailyBriefRequest,
    LLMProviderCreate,
    LLMProviderUpdate,
    TopicCreate,
    TopicUpdate,
)
from packages.storage.db import check_db_connection, session_scope
from packages.storage.repositories import (
    DailyReportConfigRepository,
    EmailConfigRepository,
    GeneratedContentRepository,
    LLMConfigRepository,
    PaperRepository,
    PipelineRunRepository,
    PromptTraceRepository,
    TopicRepository,
)

from packages.logging_setup import setup_logging

setup_logging()
logger = logging.getLogger(__name__)


def _get_paper_title(paper_id: UUID) -> str | None:
    """å¿«é€Ÿè·å–è®ºæ–‡æ ‡é¢˜"""
    try:
        with session_scope() as session:
            p = PaperRepository(session).get_by_id(paper_id)
            return (p.title or "")[:40]
    except Exception:
        return None


def _iso(dt: datetime | None) -> str | None:
    """ç¡®ä¿è¿”å›å¸¦æ—¶åŒºçš„ ISO æ ¼å¼ï¼ˆSQLite è¯»å‡ºæ¥çš„å¯èƒ½æ˜¯ naive datetimeï¼‰"""
    if dt is None:
        return None
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=UTC)
    return dt.isoformat()

api_logger = logging.getLogger("papermind.api")


class RequestLogMiddleware(BaseHTTPMiddleware):
    """è®°å½•æ¯ä¸ªè¯·æ±‚çš„æ–¹æ³•ã€è·¯å¾„ã€çŠ¶æ€ç ã€è€—æ—¶"""

    async def dispatch(self, request: Request, call_next):
        req_id = _uuid.uuid4().hex[:8]
        request.state.request_id = req_id
        start = time.perf_counter()
        response = await call_next(request)
        elapsed_ms = (time.perf_counter() - start) * 1000
        api_logger.info(
            "[%s] %s %s â†’ %d (%.0fms)",
            req_id, request.method, request.url.path,
            response.status_code, elapsed_ms,
        )
        response.headers["X-Request-Id"] = req_id
        return response


settings = get_settings()
app = FastAPI(title=settings.app_name)
app.add_middleware(RequestLogMiddleware)


@app.exception_handler(AppError)
async def app_error_handler(_request: Request, exc: AppError):
    """ç»Ÿä¸€å¤„ç†æ‰€æœ‰ä¸šåŠ¡å¼‚å¸¸ â€” è‡ªåŠ¨æ˜ å°„ status_code + ç»“æ„åŒ–å“åº”"""
    api_logger.warning(
        "[%s] %s: %s",
        exc.error_type, exc.__class__.__name__, exc.message,
    )
    return JSONResponse(status_code=exc.status_code, content=exc.to_dict())
origins = [
    x.strip()
    for x in settings.cors_allow_origins.split(",")
    if x.strip()
]
if origins:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=origins if origins != ["*"] else ["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

from packages.storage.db import run_migrations
run_migrations()

pipelines = PaperPipelines()
rag_service = RAGService()
brief_service = DailyBriefService()
graph_service = GraphService()


def _brief_date() -> str:
    return datetime.now(UTC).strftime("%Y-%m-%d")


# ---------- ç³»ç»Ÿ ----------


@app.get("/health")
def health() -> dict:
    db_ok = check_db_connection()
    status = "ok" if db_ok else "degraded"
    return {
        "status": status,
        "app": settings.app_name,
        "env": settings.app_env,
        "db": "connected" if db_ok else "unreachable",
    }


@app.get("/system/status")
def system_status() -> dict:
    with session_scope() as session:
        topics = TopicRepository(session).list_topics(enabled_only=False)
        papers = PaperRepository(session).list_latest(limit=200)
        runs = PipelineRunRepository(session).list_latest(limit=50)
        failed = [r for r in runs if r.status.value == "failed"]
        return {
            "health": health(),
            "counts": {
                "topics": len(topics),
                "enabled_topics": len([t for t in topics if t.enabled]),
                "papers_latest_200": len(papers),
                "runs_latest_50": len(runs),
                "failed_runs_latest_50": len(failed),
            },
            "latest_run": (
                {
                    "pipeline_name": runs[0].pipeline_name,
                    "status": runs[0].status.value,
                    "created_at": _iso(runs[0].created_at),
                    "error_message": runs[0].error_message,
                }
                if runs
                else None
            ),
        }


# ---------- æ‘„å…¥ ----------


@app.post("/ingest/arxiv")
def ingest_arxiv(
    query: str,
    max_results: int = Query(default=20, ge=1, le=200),
    topic_id: str | None = None,
    sort_by: str = Query(default="submittedDate", regex="^(submittedDate|relevance|lastUpdatedDate)$"),
) -> dict:
    logger.info("ArXiv ingest: query=%r max_results=%d sort=%s", query, max_results, sort_by)
    count, inserted_ids = pipelines.ingest_arxiv(
        query=query, max_results=max_results, topic_id=topic_id, sort_by=sort_by,
    )
    # æŸ¥è¯¢æ’å…¥è®ºæ–‡çš„åŸºæœ¬ä¿¡æ¯
    papers_info: list[dict] = []
    if inserted_ids:
        with session_scope() as session:
            repo = PaperRepository(session)
            for pid in inserted_ids[:50]:
                try:
                    p = repo.get_by_id(pid)
                    papers_info.append({
                        "id": p.id,
                        "title": p.title,
                        "arxiv_id": p.arxiv_id,
                        "publication_date": p.publication_date.isoformat() if p.publication_date else None,
                    })
                except Exception:
                    pass
    return {"ingested": count, "papers": papers_info}


@app.post("/ingest/references")
def ingest_references(body: ReferenceImportReq) -> dict:
    """ä¸€é”®å¯¼å…¥å‚è€ƒæ–‡çŒ® â€” è¿”å› task_id ç”¨äºè½®è¯¢è¿›åº¦"""
    from packages.ai.pipelines import ReferenceImporter
    importer = ReferenceImporter()
    task_id = importer.start_import(
        source_paper_id=body.source_paper_id,
        source_paper_title=body.source_paper_title,
        entries=[dict(e) for e in body.entries],
        topic_ids=body.topic_ids,
    )
    return {"task_id": task_id, "total": len(body.entries)}


@app.get("/ingest/references/status/{task_id}")
def ingest_references_status(task_id: str) -> dict:
    """æŸ¥è¯¢å‚è€ƒæ–‡çŒ®å¯¼å…¥ä»»åŠ¡è¿›åº¦"""
    from packages.ai.pipelines import get_import_task
    task = get_import_task(task_id)
    if not task:
        raise HTTPException(404, "Task not found")
    return task


# ---------- ä¸»é¢˜ ----------


def _topic_dict(t, session=None) -> dict:
    d = {
        "id": t.id,
        "name": t.name,
        "query": t.query,
        "enabled": t.enabled,
        "max_results_per_run": t.max_results_per_run,
        "retry_limit": t.retry_limit,
        "schedule_frequency": getattr(t, "schedule_frequency", "daily"),
        "schedule_time_utc": getattr(t, "schedule_time_utc", 21),
        "paper_count": 0,
        "last_run_at": None,
        "last_run_count": None,
    }
    if session is not None:
        from sqlalchemy import func, select
        from packages.storage.models import PaperTopic, CollectionAction
        # è®ºæ–‡è®¡æ•°
        cnt = session.scalar(
            select(func.count()).select_from(PaperTopic)
            .where(PaperTopic.topic_id == t.id)
        )
        d["paper_count"] = cnt or 0
        # æœ€è¿‘ä¸€æ¬¡è¡ŒåŠ¨
        last_action = session.execute(
            select(CollectionAction)
            .where(CollectionAction.topic_id == t.id)
            .order_by(CollectionAction.created_at.desc())
            .limit(1)
        ).scalar_one_or_none()
        if last_action:
            d["last_run_at"] = last_action.created_at.isoformat() if last_action.created_at else None
            d["last_run_count"] = last_action.paper_count
    return d


@app.get("/topics")
def list_topics(enabled_only: bool = False) -> dict:
    with session_scope() as session:
        topics = TopicRepository(session).list_topics(
            enabled_only=enabled_only
        )
        return {"items": [_topic_dict(t, session) for t in topics]}


@app.post("/topics")
def upsert_topic(req: TopicCreate) -> dict:
    with session_scope() as session:
        topic = TopicRepository(session).upsert_topic(
            name=req.name,
            query=req.query,
            enabled=req.enabled,
            max_results_per_run=req.max_results_per_run,
            retry_limit=req.retry_limit,
            schedule_frequency=req.schedule_frequency,
            schedule_time_utc=req.schedule_time_utc,
        )
        return _topic_dict(topic, session)


@app.patch("/topics/{topic_id}")
def update_topic(topic_id: str, req: TopicUpdate) -> dict:
    with session_scope() as session:
        try:
            topic = TopicRepository(session).update_topic(
                topic_id,
                query=req.query,
                enabled=req.enabled,
                max_results_per_run=req.max_results_per_run,
                retry_limit=req.retry_limit,
                schedule_frequency=req.schedule_frequency,
                schedule_time_utc=req.schedule_time_utc,
            )
        except ValueError as exc:
            raise NotFoundError(str(exc)) from exc
        return _topic_dict(topic, session)


@app.delete("/topics/{topic_id}")
def delete_topic(topic_id: str) -> dict:
    with session_scope() as session:
        TopicRepository(session).delete_topic(topic_id)
        return {"deleted": topic_id}


@app.post("/topics/{topic_id}/fetch")
def manual_fetch_topic(topic_id: str) -> dict:
    """æ‰‹åŠ¨è§¦å‘å•ä¸ªè®¢é˜…çš„è®ºæ–‡æŠ“å–ï¼ˆåå°æ‰§è¡Œï¼Œç«‹å³è¿”å›ï¼‰"""
    from packages.ai.daily_runner import run_topic_ingest
    from packages.storage.models import TopicSubscription
    with session_scope() as session:
        topic = session.get(TopicSubscription, topic_id)
        if not topic:
            raise NotFoundError("è®¢é˜…ä¸å­˜åœ¨")
        topic_name = topic.name

    def _fetch_fn(progress_callback=None):
        return run_topic_ingest(topic_id)

    task_id = global_tracker.submit(
        task_type="fetch",
        title=f"æŠ“å–: {topic_name[:30]}",
        fn=_fetch_fn,
    )
    return {
        "status": "started",
        "task_id": task_id,
        "topic_id": topic_id,
        "topic_name": topic_name,
        "message": f"ã€Œ{topic_name}ã€æŠ“å–å·²åœ¨åå°å¯åŠ¨",
    }


@app.get("/topics/{topic_id}/fetch-status")
def fetch_topic_status(topic_id: str) -> dict:
    """æŸ¥è¯¢æ‰‹åŠ¨æŠ“å–çš„æ‰§è¡ŒçŠ¶æ€ â€” é€šè¿‡å…¨å±€ tracker æŸ¥è¯¢"""
    # å…¼å®¹æ—§çš„è½®è¯¢é€»è¾‘ï¼šä» tracker ä¸­æ‰¾åŒ¹é…çš„ fetch ä»»åŠ¡
    active = global_tracker.get_active()
    for t in active:
        if t["task_type"] == "fetch" and topic_id[:8] in t.get("task_id", ""):
            if t["finished"]:
                return {"status": "completed" if t["success"] else "failed", **t}
            return {"status": "running", **t}
    # æ²¡æ‰¾åˆ°æ´»è·ƒä»»åŠ¡ï¼Œçœ‹ DB é‡Œçš„ä¸»é¢˜ä¿¡æ¯
    with session_scope() as session:
        from packages.storage.models import TopicSubscription
        topic = session.get(TopicSubscription, topic_id)
        topic_info = _topic_dict(topic, session) if topic else {}
    return {**task, "topic": topic_info}


@app.post("/topics/suggest-keywords")
def suggest_keywords(req: SuggestKeywordsReq) -> dict:
    from packages.ai.keyword_service import KeywordService
    description = req.description
    if not description.strip():
        raise HTTPException(400, "description is required")
    suggestions = KeywordService().suggest(description.strip())
    return {"suggestions": suggestions}


# ---------- å¼•ç”¨åŒæ­¥ ----------
# æ³¨æ„ï¼šå›ºå®šè·¯å¾„å¿…é¡»åœ¨ {paper_id} åŠ¨æ€è·¯å¾„ä¹‹å‰ï¼Œå¦åˆ™ä¼šè¢«é”™è¯¯åŒ¹é…


@app.post("/citations/sync/incremental")
def sync_citations_incremental(
    paper_limit: int = Query(default=40, ge=1, le=200),
    edge_limit_per_paper: int = Query(default=6, ge=1, le=50),
) -> dict:
    """å¢é‡åŒæ­¥å¼•ç”¨ï¼ˆåå°æ‰§è¡Œï¼‰"""
    def _fn(progress_callback=None):
        return graph_service.sync_incremental(
            paper_limit=paper_limit,
            edge_limit_per_paper=edge_limit_per_paper,
        )

    task_id = global_tracker.submit("citation_sync", "ğŸ“Š å¢é‡å¼•ç”¨åŒæ­¥", _fn)
    return {"task_id": task_id, "message": "å¢é‡å¼•ç”¨åŒæ­¥å·²å¯åŠ¨", "status": "running"}


@app.post("/citations/sync/topic/{topic_id}")
def sync_citations_for_topic(
    topic_id: str,
    paper_limit: int = Query(default=30, ge=1, le=200),
    edge_limit_per_paper: int = Query(default=6, ge=1, le=50),
) -> dict:
    """ä¸»é¢˜å¼•ç”¨åŒæ­¥ï¼ˆåå°æ‰§è¡Œï¼‰"""
    topic_name = topic_id
    try:
        with session_scope() as session:
            topic = TopicRepository(session).get_by_id(topic_id)
            if topic:
                topic_name = topic.name
    except Exception:
        pass

    def _fn(progress_callback=None):
        return graph_service.sync_citations_for_topic(
            topic_id=topic_id,
            paper_limit=paper_limit,
            edge_limit_per_paper=edge_limit_per_paper,
        )

    task_id = global_tracker.submit("citation_sync", f"ğŸ“Š ä¸»é¢˜å¼•ç”¨åŒæ­¥: {topic_name}", _fn)
    return {"task_id": task_id, "message": f"ä¸»é¢˜å¼•ç”¨åŒæ­¥å·²å¯åŠ¨: {topic_name}", "status": "running"}


@app.post("/citations/sync/{paper_id}")
def sync_citations(
    paper_id: str,
    limit: int = Query(default=8, ge=1, le=50),
) -> dict:
    """å•ç¯‡è®ºæ–‡å¼•ç”¨åŒæ­¥ï¼ˆåå°æ‰§è¡Œï¼‰"""
    paper_title = _get_paper_title(UUID(paper_id)) or paper_id[:8]

    def _fn(progress_callback=None):
        return graph_service.sync_citations_for_paper(paper_id=paper_id, limit=limit)

    task_id = global_tracker.submit("citation_sync", f"ğŸ“„ å¼•ç”¨åŒæ­¥: {paper_title[:30]}", _fn)
    return {"task_id": task_id, "message": "è®ºæ–‡å¼•ç”¨åŒæ­¥å·²å¯åŠ¨", "status": "running"}


# ---------- å›¾è°± ----------


@app.get("/graph/similarity-map")
def similarity_map(
    topic_id: str | None = None,
    limit: int = Query(default=200, ge=5, le=500),
) -> dict:
    """è®ºæ–‡ç›¸ä¼¼åº¦ 2D æ•£ç‚¹å›¾ï¼ˆUMAP é™ç»´ï¼‰"""
    return graph_service.similarity_map(topic_id=topic_id, limit=limit)


@app.get("/graph/citation-tree/{paper_id}")
def citation_tree(
    paper_id: str,
    depth: int = Query(default=2, ge=1, le=5),
) -> dict:
    return graph_service.citation_tree(
        root_paper_id=paper_id, depth=depth
    )


@app.get("/graph/citation-detail/{paper_id}")
def citation_detail(paper_id: str) -> dict:
    """è·å–å•ç¯‡è®ºæ–‡çš„ä¸°å¯Œå¼•ç”¨è¯¦æƒ…ï¼ˆå«å‚è€ƒæ–‡çŒ®å’Œè¢«å¼•åˆ—è¡¨ï¼‰"""
    return graph_service.citation_detail(paper_id=paper_id)


@app.get("/graph/citation-network/topic/{topic_id}")
def topic_citation_network(topic_id: str) -> dict:
    """è·å–ä¸»é¢˜å†…è®ºæ–‡çš„äº’å¼•ç½‘ç»œ"""
    return graph_service.topic_citation_network(topic_id=topic_id)


@app.post("/graph/citation-network/topic/{topic_id}/deep-trace")
def topic_deep_trace(topic_id: str) -> dict:
    """å¯¹ä¸»é¢˜å†…è®ºæ–‡æ‰§è¡Œæ·±åº¦æº¯æºï¼Œæ‹‰å–å¤–éƒ¨å¼•ç”¨å¹¶è¿›è¡Œå…±å¼•åˆ†æ"""
    return graph_service.topic_deep_trace(topic_id=topic_id)


@app.get("/graph/overview")
def graph_overview() -> dict:
    """å…¨åº“å¼•ç”¨æ¦‚è§ˆ â€” èŠ‚ç‚¹ + è¾¹ + PageRank + ç»Ÿè®¡"""
    return graph_service.library_overview()


@app.get("/graph/bridges")
def graph_bridges() -> dict:
    """è·¨ä¸»é¢˜æ¡¥æ¥è®ºæ–‡"""
    return graph_service.cross_topic_bridges()


@app.get("/graph/frontier")
def graph_frontier(
    days: int = Query(default=90, ge=7, le=365),
) -> dict:
    """ç ”ç©¶å‰æ²¿æ£€æµ‹"""
    return graph_service.research_frontier(days=days)


@app.get("/graph/cocitation-clusters")
def graph_cocitation_clusters(
    min_cocite: int = Query(default=2, ge=1, le=10),
) -> dict:
    """å…±å¼•èšç±»åˆ†æ"""
    return graph_service.cocitation_clusters(min_cocite=min_cocite)


@app.post("/graph/auto-link")
def graph_auto_link(paper_ids: list[str]) -> dict:
    """æ‰‹åŠ¨è§¦å‘å¼•ç”¨è‡ªåŠ¨å…³è”"""
    return graph_service.auto_link_citations(paper_ids)


@app.get("/graph/timeline")
def graph_timeline(
    keyword: str,
    limit: int = Query(default=100, ge=1, le=500),
) -> dict:
    return graph_service.timeline(keyword=keyword, limit=limit)


@app.get("/graph/quality")
def graph_quality(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    return graph_service.quality_metrics(keyword=keyword, limit=limit)


@app.get("/graph/evolution/weekly")
def graph_weekly_evolution(
    keyword: str,
    limit: int = Query(default=160, ge=1, le=500),
) -> dict:
    return graph_service.weekly_evolution(keyword=keyword, limit=limit)


@app.get("/graph/survey")
def graph_survey(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    return graph_service.survey(keyword=keyword, limit=limit)


@app.get("/graph/research-gaps")
def graph_research_gaps(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    return graph_service.detect_research_gaps(keyword=keyword, limit=limit)


@app.post("/papers/{paper_id}/reasoning")
def paper_reasoning(paper_id: UUID) -> dict:
    """æ¨ç†é“¾æ·±åº¦åˆ†æ"""
    from packages.ai.reasoning_service import ReasoningService
    with session_scope() as session:
        repo = PaperRepository(session)
        try:
            repo.get_by_id(paper_id)
        except ValueError as exc:
            raise HTTPException(status_code=404, detail=str(exc)) from exc
    return ReasoningService().analyze(paper_id)


# ---------- Wiki ----------


@app.get("/wiki/paper/{paper_id}")
def wiki_paper(paper_id: str) -> dict:
    result = graph_service.paper_wiki(paper_id=paper_id)
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        gc = repo.create(
            content_type="paper_wiki",
            title=f"Paper Wiki: {result.get('title', paper_id)}",
            markdown=result.get("markdown", ""),
            paper_id=paper_id,
            metadata_json={
                k: v for k, v in result.items() if k != "markdown"
            },
        )
        result["content_id"] = gc.id
    return result


@app.get("/wiki/topic")
def wiki_topic(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    result = graph_service.topic_wiki(keyword=keyword, limit=limit)
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        gc = repo.create(
            content_type="topic_wiki",
            title=f"Topic Wiki: {keyword}",
            markdown=result.get("markdown", ""),
            keyword=keyword,
            metadata_json={
                k: v for k, v in result.items() if k != "markdown"
            },
        )
        result["content_id"] = gc.id
    return result


# ---------- å¼‚æ­¥ä»»åŠ¡ API ----------


def _run_topic_wiki_task(
    keyword: str,
    limit: int,
    progress_callback=None,
) -> dict:
    """åå°æ‰§è¡Œ topic wiki ç”Ÿæˆ"""
    result = graph_service.topic_wiki(
        keyword=keyword, limit=limit,
        progress_callback=progress_callback,
    )
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        gc = repo.create(
            content_type="topic_wiki",
            title=f"Topic Wiki: {keyword}",
            markdown=result.get("markdown", ""),
            keyword=keyword,
            metadata_json={
                k: v for k, v in result.items() if k != "markdown"
            },
        )
        result["content_id"] = gc.id
    return result


@app.post("/tasks/wiki/topic")
def start_topic_wiki_task(
    keyword: str,
    limit: int = Query(default=120, ge=1, le=500),
) -> dict:
    """æäº¤åå° wiki ç”Ÿæˆä»»åŠ¡"""
    task_id = global_tracker.submit(
        task_type="topic_wiki",
        title=f"Wiki: {keyword}",
        fn=_run_topic_wiki_task,
        keyword=keyword,
        limit=limit,
    )
    return {"task_id": task_id, "status": "pending"}


@app.get("/tasks/active")
def get_active_tasks() -> dict:
    """è·å–å…¨å±€è¿›è¡Œä¸­çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆè·¨é¡µé¢å¯è§ï¼‰"""

    return {"tasks": global_tracker.get_active()}


@app.post("/tasks/track")
def track_task(body: dict) -> dict:
    """å‰ç«¯é€šçŸ¥åç«¯åˆ›å»º/æ›´æ–°/å®Œæˆä¸€ä¸ªå…¨å±€å¯è§ä»»åŠ¡"""

    action = body.get("action", "start")
    task_id = body.get("task_id", "")
    if action == "start":
        global_tracker.start(
            task_id=task_id,
            task_type=body.get("task_type", "batch"),
            title=body.get("title", ""),
            total=body.get("total", 0),
        )
    elif action == "update":
        global_tracker.update(
            task_id=task_id,
            current=body.get("current", 0),
            message=body.get("message", ""),
            total=body.get("total"),
        )
    elif action == "finish":
        global_tracker.finish(
            task_id=task_id,
            success=body.get("success", True),
            error=body.get("error"),
        )
    return {"ok": True}


@app.get("/tasks/{task_id}")
def get_task_status(task_id: str) -> dict:
    """æŸ¥è¯¢ä»»åŠ¡è¿›åº¦"""
    status = global_tracker.get_task(task_id)
    if not status:
        raise NotFoundError(f"Task {task_id} not found")
    return status


@app.get("/tasks/{task_id}/result")
def get_task_result(task_id: str) -> dict:
    """è·å–å·²å®Œæˆä»»åŠ¡çš„ç»“æœ"""
    status = global_tracker.get_task(task_id)
    if not status:
        raise NotFoundError(f"Task {task_id} not found")
    if not status.get("finished"):
        raise HTTPException(400, f"Task not finished yet")
    result = global_tracker.get_result(task_id)
    return result or {}


# ---------- Pipeline ----------


@app.post("/pipelines/skim/{paper_id}")
def run_skim(paper_id: UUID) -> dict:

    tid = f"skim_{paper_id.hex[:8]}"
    title = _get_paper_title(paper_id) or str(paper_id)[:8]
    global_tracker.start(tid, "skim", f"ç²—è¯»: {title[:30]}", total=1)
    try:
        skim = pipelines.skim(paper_id)
        global_tracker.finish(tid, success=True)
        return skim.model_dump()
    except Exception as exc:
        global_tracker.finish(tid, success=False, error=str(exc)[:100])
        raise


@app.post("/pipelines/deep/{paper_id}")
def run_deep(paper_id: UUID) -> dict:

    tid = f"deep_{paper_id.hex[:8]}"
    title = _get_paper_title(paper_id) or str(paper_id)[:8]
    global_tracker.start(tid, "deep_read", f"ç²¾è¯»: {title[:30]}", total=1)
    try:
        deep = pipelines.deep_dive(paper_id)
        global_tracker.finish(tid, success=True)
        return deep.model_dump()
    except Exception as exc:
        global_tracker.finish(tid, success=False, error=str(exc)[:100])
        raise


@app.post("/pipelines/embed/{paper_id}")
def run_embed(paper_id: UUID) -> dict:

    tid = f"embed_{paper_id.hex[:8]}"
    title = _get_paper_title(paper_id) or str(paper_id)[:8]
    global_tracker.start(tid, "embed", f"åµŒå…¥: {title[:30]}", total=1)
    try:
        pipelines.embed_paper(paper_id)
        global_tracker.finish(tid, success=True)
        return {"status": "embedded", "paper_id": str(paper_id)}
    except Exception as exc:
        global_tracker.finish(tid, success=False, error=str(exc)[:100])
        raise


@app.get("/pipelines/runs")
def list_pipeline_runs(
    limit: int = Query(default=30, ge=1, le=200),
) -> dict:
    with session_scope() as session:
        runs = PipelineRunRepository(session).list_latest(limit=limit)
        return {
            "items": [
                {
                    "id": r.id,
                    "pipeline_name": r.pipeline_name,
                    "paper_id": r.paper_id,
                    "status": r.status.value,
                    "decision_note": r.decision_note,
                    "elapsed_ms": r.elapsed_ms,
                    "error_message": r.error_message,
                    "created_at": _iso(r.created_at),
                }
                for r in runs
            ]
        }


# ---------- RAG ----------


@app.post("/rag/ask", response_model=AskResponse)
def ask(req: AskRequest) -> AskResponse:
    logger.info("RAG ask: question=%r", req.question[:80])
    return rag_service.ask(req.question, top_k=req.top_k)


@app.post("/rag/ask-iterative")
def ask_iterative(
    req: AskRequest,
    max_rounds: int = Query(default=3, ge=1, le=5),
) -> dict:
    """å¤šè½®è¿­ä»£ RAG"""
    logger.info("RAG iterative ask: question=%r max_rounds=%d", req.question[:80], max_rounds)
    resp = rag_service.ask_iterative(
        question=req.question,
        max_rounds=max_rounds,
        initial_top_k=req.top_k,
    )
    return resp.model_dump(mode="json")


@app.get("/papers/{paper_id}/similar")
def similar(
    paper_id: UUID,
    top_k: int = Query(default=5, ge=1, le=20),
) -> dict:
    ids = rag_service.similar_papers(paper_id, top_k=top_k)
    items = []
    if ids:
        with session_scope() as session:
            repo = PaperRepository(session)
            for pid in ids:
                try:
                    p = repo.get_by_id(pid)
                    items.append({
                        "id": str(p.id),
                        "title": p.title,
                        "arxiv_id": p.arxiv_id,
                        "read_status": p.read_status.value if p.read_status else "unread",
                    })
                except Exception:
                    items.append({"id": str(pid), "title": str(pid), "arxiv_id": None, "read_status": "unread"})
    return {
        "paper_id": str(paper_id),
        "similar_ids": [str(x) for x in ids],
        "items": items,
    }


# ---------- è®ºæ–‡ ----------


@app.get("/papers/folder-stats")
def paper_folder_stats() -> dict:
    """è®ºæ–‡æ–‡ä»¶å¤¹ç»Ÿè®¡"""
    with session_scope() as session:
        repo = PaperRepository(session)
        return repo.folder_stats()


def _paper_list_response(papers: list, repo: "PaperRepository") -> dict:
    """è®ºæ–‡åˆ—è¡¨ç»Ÿä¸€åºåˆ—åŒ–"""
    paper_ids = [str(p.id) for p in papers]
    topic_map = repo.get_topic_names_for_papers(paper_ids)
    return {
        "items": [
            {
                "id": str(p.id),
                "title": p.title,
                "arxiv_id": p.arxiv_id,
                "abstract": p.abstract,
                "publication_date": str(p.publication_date) if p.publication_date else None,
                "read_status": p.read_status.value,
                "pdf_path": p.pdf_path,
                "has_embedding": p.embedding is not None,
                "favorited": getattr(p, "favorited", False),
                "categories": (p.metadata_json or {}).get("categories", []),
                "keywords": (p.metadata_json or {}).get("keywords", []),
                "title_zh": (p.metadata_json or {}).get("title_zh", ""),
                "abstract_zh": (p.metadata_json or {}).get("abstract_zh", ""),
                "topics": topic_map.get(str(p.id), []),
            }
            for p in papers
        ]
    }


@app.get("/papers/latest")
def latest(
    limit: int = Query(default=50, ge=1, le=500),
    page: int = Query(default=1, ge=1),
    page_size: int = Query(default=20, ge=1, le=100),
    status: str | None = Query(default=None),
    topic_id: str | None = Query(default=None),
    folder: str | None = Query(default=None),
    date: str | None = Query(default=None),
    search: str | None = Query(default=None),
) -> dict:
    with session_scope() as session:
        repo = PaperRepository(session)
        papers, total = repo.list_paginated(
            page=page,
            page_size=page_size,
            folder=folder,
            topic_id=topic_id,
            status=status,
            date_str=date,
            search=search.strip() if search else None,
        )
        resp = _paper_list_response(papers, repo)
        resp["total"] = total
        resp["page"] = page
        resp["page_size"] = page_size
        resp["total_pages"] = max(1, (total + page_size - 1) // page_size)
        return resp


@app.get("/papers/recommended")
def recommended_papers(top_k: int = Query(default=10, ge=1, le=50)) -> dict:
    from packages.ai.recommendation_service import RecommendationService
    return {"items": RecommendationService().recommend(top_k=top_k)}


@app.get("/papers/{paper_id}")
def paper_detail(paper_id: UUID) -> dict:
    with session_scope() as session:
        repo = PaperRepository(session)
        try:
            p = repo.get_by_id(paper_id)
        except ValueError as exc:
            raise HTTPException(
                status_code=404, detail=str(exc)
            ) from exc
        topic_map = repo.get_topic_names_for_papers([str(p.id)])
        # æŸ¥è¯¢å·²æœ‰åˆ†ææŠ¥å‘Š
        from packages.storage.models import AnalysisReport as AR
        from sqlalchemy import select as _sel
        ar = session.execute(
            _sel(AR).where(AR.paper_id == str(p.id))
        ).scalar_one_or_none()
        skim_data = None
        deep_data = None
        if ar:
            if ar.summary_md:
                skim_data = {
                    "summary_md": ar.summary_md,
                    "skim_score": ar.skim_score,
                    "key_insights": ar.key_insights or {},
                }
            if ar.deep_dive_md:
                deep_data = {
                    "deep_dive_md": ar.deep_dive_md,
                    "key_insights": ar.key_insights or {},
                }
        return {
            "id": str(p.id),
            "title": p.title,
            "arxiv_id": p.arxiv_id,
            "abstract": p.abstract,
            "publication_date": str(p.publication_date) if p.publication_date else None,
            "read_status": p.read_status.value,
            "pdf_path": p.pdf_path,
            "favorited": getattr(p, "favorited", False),
            "categories": (p.metadata_json or {}).get("categories", []),
            "authors": (p.metadata_json or {}).get("authors", []),
            "keywords": (p.metadata_json or {}).get("keywords", []),
            "title_zh": (p.metadata_json or {}).get("title_zh", ""),
            "abstract_zh": (p.metadata_json or {}).get("abstract_zh", ""),
            "topics": topic_map.get(str(p.id), []),
            "metadata": p.metadata_json,
            "has_embedding": p.embedding is not None,
            "skim_report": skim_data,
            "deep_report": deep_data,
        }


@app.patch("/papers/{paper_id}/favorite")
def toggle_favorite(paper_id: UUID) -> dict:
    """åˆ‡æ¢è®ºæ–‡æ”¶è—çŠ¶æ€"""
    with session_scope() as session:
        repo = PaperRepository(session)
        try:
            p = repo.get_by_id(paper_id)
        except ValueError as exc:
            raise HTTPException(status_code=404, detail=str(exc)) from exc
        current = getattr(p, "favorited", False)
        p.favorited = not current
        session.commit()
        return {"id": str(p.id), "favorited": p.favorited}


# ---------- PDF æœåŠ¡ ----------


@app.post("/papers/{paper_id}/download-pdf")
def download_paper_pdf(paper_id: UUID) -> dict:
    """ä» arXiv ä¸‹è½½è®ºæ–‡ PDF"""
    from packages.integrations.arxiv_client import ArxivClient
    with session_scope() as session:
        repo = PaperRepository(session)
        try:
            paper = repo.get_by_id(paper_id)
        except ValueError as exc:
            raise HTTPException(status_code=404, detail=str(exc)) from exc
        if paper.pdf_path and Path(paper.pdf_path).exists():
            return {"status": "exists", "pdf_path": paper.pdf_path}
        if not paper.arxiv_id or paper.arxiv_id.startswith("ss-"):
            raise HTTPException(status_code=400, detail="è¯¥è®ºæ–‡æ²¡æœ‰æœ‰æ•ˆçš„ arXiv IDï¼Œæ— æ³•ä¸‹è½½ PDF")
        try:
            pdf_path = ArxivClient().download_pdf(paper.arxiv_id)
            repo.set_pdf_path(paper_id, pdf_path)
            return {"status": "downloaded", "pdf_path": pdf_path}
        except Exception as exc:
            raise HTTPException(status_code=500, detail=f"PDF ä¸‹è½½å¤±è´¥: {exc}") from exc


@app.get("/papers/{paper_id}/pdf")
def serve_paper_pdf(paper_id: UUID) -> FileResponse:
    """æä¾›è®ºæ–‡ PDF æ–‡ä»¶ä¸‹è½½/é¢„è§ˆ"""
    with session_scope() as session:
        repo = PaperRepository(session)
        try:
            paper = repo.get_by_id(paper_id)
        except ValueError as exc:
            raise HTTPException(status_code=404, detail=str(exc)) from exc
        pdf_path = paper.pdf_path
    if not pdf_path:
        raise HTTPException(status_code=404, detail="è®ºæ–‡æ²¡æœ‰ PDF æ–‡ä»¶")
    full_path = Path(pdf_path)
    if not full_path.exists():
        raise HTTPException(status_code=404, detail="PDF æ–‡ä»¶ä¸å­˜åœ¨")
    return FileResponse(
        path=str(full_path),
        media_type="application/pdf",
        headers={"Access-Control-Allow-Origin": "*"},
    )


@app.post("/papers/{paper_id}/ai/explain")
def ai_explain_text(paper_id: UUID, body: AIExplainReq) -> dict:
    """AI è§£é‡Š/ç¿»è¯‘é€‰ä¸­æ–‡æœ¬"""
    text = body.text.strip()
    action = body.action
    if not text:
        raise HTTPException(status_code=400, detail="text is required")

    prompts = {
        "explain": (
            f"ä½ æ˜¯å­¦æœ¯è®ºæ–‡è§£è¯»ä¸“å®¶ã€‚è¯·ç”¨ä¸­æ–‡ç®€æ´è§£é‡Šä»¥ä¸‹å­¦æœ¯æ–‡æœ¬çš„å«ä¹‰ï¼Œ"
            f"åŒ…æ‹¬ä¸“ä¸šæœ¯è¯­è§£é‡Šå’Œæ ¸å¿ƒæ„æ€ã€‚å¦‚æœæ˜¯å…¬å¼ï¼Œè§£é‡Šå…¬å¼çš„å«ä¹‰å’Œå„å˜é‡ã€‚\n\n"
            f"æ–‡æœ¬ï¼š{text[:2000]}"
        ),
        "translate": (
            f"è¯·å°†ä»¥ä¸‹å­¦æœ¯æ–‡æœ¬ç¿»è¯‘ä¸ºæµç•…çš„ä¸­æ–‡ï¼Œä¿ç•™ä¸“ä¸šæœ¯è¯­çš„è‹±æ–‡åŸæ–‡ï¼ˆæ‹¬å·æ ‡æ³¨ï¼‰ã€‚\n\n"
            f"æ–‡æœ¬ï¼š{text[:2000]}"
        ),
        "summarize": (
            f"è¯·ç”¨ä¸­æ–‡ç®€è¦æ€»ç»“ä»¥ä¸‹å†…å®¹çš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ3-5 å¥è¯ï¼‰ï¼š\n\n{text[:3000]}"
        ),
    }
    prompt = prompts.get(action, prompts["explain"])

    from packages.integrations.llm_client import LLMClient
    llm = LLMClient()
    result = llm.summarize_text(prompt, stage="rag", max_tokens=1024)
    llm.trace_result(result, stage="pdf_reader_ai", prompt_digest=f"{action}:{text[:80]}", paper_id=str(paper_id))
    return {"action": action, "result": result.content}


# ---------- å›¾è¡¨è§£è¯» ----------


@app.get("/papers/{paper_id}/figures")
def get_paper_figures(paper_id: UUID) -> dict:
    """è·å–è®ºæ–‡å·²æœ‰çš„å›¾è¡¨è§£è¯»"""
    from packages.ai.figure_service import FigureService
    items = FigureService.get_paper_analyses(paper_id)
    for item in items:
        if item.get("has_image"):
            item["image_url"] = f"/papers/{paper_id}/figures/{item['id']}/image"
        else:
            item["image_url"] = None
    return {"items": items}


@app.get("/papers/{paper_id}/figures/{figure_id}/image")
def get_figure_image(paper_id: UUID, figure_id: str):
    """è¿”å›å›¾è¡¨åŸå§‹å›¾ç‰‡æ–‡ä»¶"""
    from packages.storage.db import session_scope
    from packages.storage.models import ImageAnalysis
    from sqlalchemy import select

    with session_scope() as session:
        row = session.execute(
            select(ImageAnalysis).where(
                ImageAnalysis.id == figure_id,
                ImageAnalysis.paper_id == str(paper_id),
            )
        ).scalar_one_or_none()

        if not row or not row.image_path:
            raise HTTPException(status_code=404, detail="å›¾ç‰‡ä¸å­˜åœ¨")

        img_path = Path(row.image_path)
        if not img_path.exists():
            raise HTTPException(status_code=404, detail="å›¾ç‰‡æ–‡ä»¶ä¸¢å¤±")

        return FileResponse(img_path, media_type="image/png")


@app.post("/papers/{paper_id}/figures/analyze")
def analyze_paper_figures(
    paper_id: UUID,
    max_figures: int = Query(default=10, ge=1, le=30),
) -> dict:
    """æå–å¹¶è§£è¯»è®ºæ–‡ä¸­çš„å›¾è¡¨"""
    from packages.ai.figure_service import FigureService
    with session_scope() as session:
        repo = PaperRepository(session)
        try:
            paper = repo.get_by_id(paper_id)
        except ValueError as exc:
            raise HTTPException(status_code=404, detail=str(exc)) from exc
        if not paper.pdf_path:
            raise HTTPException(status_code=400, detail="è®ºæ–‡æ²¡æœ‰ PDF æ–‡ä»¶")
        pdf_path = paper.pdf_path  # åœ¨ session å†…å–å‡º
    svc = FigureService()
    try:
        results = svc.analyze_paper_figures(paper_id, pdf_path, max_figures)
    except Exception as exc:
        raise HTTPException(status_code=500, detail=f"å›¾è¡¨è§£è¯»å¤±è´¥: {exc}") from exc
    # åˆ†æå®Œæˆåï¼Œä» DB è·å–å¸¦ id çš„å®Œæ•´ç»“æœï¼ˆå« image_urlï¼‰
    from packages.ai.figure_service import FigureService as FS2
    items = FS2.get_paper_analyses(paper_id)
    for item in items:
        if item.get("has_image"):
            item["image_url"] = f"/papers/{paper_id}/figures/{item['id']}/image"
        else:
            item["image_url"] = None
    return {
        "paper_id": str(paper_id),
        "count": len(items),
        "items": items,
    }


# ---------- ç®€æŠ¥ ----------


@app.post("/brief/daily")
def daily_brief(req: DailyBriefRequest) -> dict:
    recipient = req.recipient or settings.notify_default_to
    html_content = brief_service.build_html()
    result = brief_service.publish(recipient=recipient)
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        ts = _brief_date()
        gc = repo.create(
            content_type="daily_brief",
            title=f"Daily Brief: {ts}",
            markdown=html_content,
            metadata_json={
                "saved_path": result.get("saved_path", ""),
                "email_sent": result.get("email_sent", False),
            },
        )
        result["content_id"] = gc.id
    return result


# ---------- ç”Ÿæˆå†…å®¹å†å² ----------


@app.get("/generated/list")
def generated_list(
    type: str = Query(..., description="content_type: topic_wiki|paper_wiki|daily_brief"),
    limit: int = Query(default=50, ge=1, le=200),
) -> dict:
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        items = repo.list_by_type(type, limit=limit)
        return {
            "items": [
                {
                    "id": gc.id,
                    "content_type": gc.content_type,
                    "title": gc.title,
                    "keyword": gc.keyword,
                    "paper_id": gc.paper_id,
                    "created_at": _iso(gc.created_at),
                }
                for gc in items
            ]
        }


@app.get("/generated/{content_id}")
def generated_detail(content_id: str) -> dict:
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        try:
            gc = repo.get_by_id(content_id)
        except ValueError:
            raise HTTPException(status_code=404, detail="Content not found")
        return {
            "id": gc.id,
            "content_type": gc.content_type,
            "title": gc.title,
            "keyword": gc.keyword,
            "paper_id": gc.paper_id,
            "markdown": gc.markdown,
            "metadata_json": gc.metadata_json,
            "created_at": _iso(gc.created_at),
        }


@app.delete("/generated/{content_id}")
def generated_delete(content_id: str) -> dict:
    with session_scope() as session:
        repo = GeneratedContentRepository(session)
        try:
            repo.get_by_id(content_id)
        except ValueError:
            raise HTTPException(status_code=404, detail="Content not found")
        repo.delete(content_id)
    return {"deleted": content_id}


# ---------- å®šæ—¶ä»»åŠ¡ ----------


@app.post("/jobs/daily/run-once")
def run_daily_once() -> dict:
    """æ¯æ—¥ä»»åŠ¡ï¼ˆæŠ“å–+ç®€æŠ¥ï¼‰- åå°æ‰§è¡Œ"""
    def _fn(progress_callback=None):
        if progress_callback:
            progress_callback("æ­£åœ¨æ‰§è¡Œè®¢é˜…æ”¶é›†...", 10, 100)
        ingest = run_daily_ingest()
        if progress_callback:
            progress_callback("æ­£åœ¨ç”Ÿæˆæ¯æ—¥ç®€æŠ¥...", 70, 100)
        brief = run_daily_brief()
        return {"ingest": ingest, "brief": brief}

    task_id = global_tracker.submit("daily_job", "ğŸ“… æ¯æ—¥ä»»åŠ¡æ‰§è¡Œ", _fn)
    return {"task_id": task_id, "message": "æ¯æ—¥ä»»åŠ¡å·²å¯åŠ¨", "status": "running"}


@app.post("/jobs/graph/weekly-run-once")
def run_weekly_graph_once() -> dict:
    """æ¯å‘¨å›¾ç»´æŠ¤ä»»åŠ¡ - åå°æ‰§è¡Œ"""
    def _fn(progress_callback=None):
        return run_weekly_graph_maintenance()

    task_id = global_tracker.submit("weekly_maintenance", "ğŸ”„ æ¯å‘¨å›¾ç»´æŠ¤", _fn)
    return {"task_id": task_id, "message": "æ¯å‘¨å›¾ç»´æŠ¤å·²å¯åŠ¨", "status": "running"}


@app.post("/jobs/batch-process-unread")
def batch_process_unread(
    background_tasks: BackgroundTasks,
    max_papers: int = Query(default=50, ge=1, le=200),
) -> dict:
    """æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡ï¼ˆembed + skim å¹¶è¡Œï¼‰- åå°æ‰§è¡Œ"""
    import uuid
    from concurrent.futures import ThreadPoolExecutor, as_completed

    from packages.ai.daily_runner import _process_paper, PAPER_CONCURRENCY

    # å…ˆè·å–éœ€è¦å¤„ç†çš„è®ºæ–‡æ•°é‡
    with session_scope() as session:
        repo = PaperRepository(session)
        unread = repo.list_by_read_status(ReadStatus.unread, limit=max_papers)
        target_ids = []
        for p in unread:
            needs_embed = p.embedding is None
            needs_skim = p.read_status == ReadStatus.unread
            if needs_embed or needs_skim:
                target_ids.append(p.id)

    total = len(target_ids)
    if total == 0:
        return {"processed": 0, "total_unread": 0, "message": "æ²¡æœ‰éœ€è¦å¤„ç†çš„æœªè¯»è®ºæ–‡"}

    task_id = f"batch_unread_{uuid.uuid4().hex[:8]}"

    def _run_batch():
        processed = 0
        failed = 0
        try:
            global_tracker.start(task_id, "batch_process", f"ğŸ“š æ‰¹é‡å¤„ç†æœªè¯»è®ºæ–‡ ({total} ç¯‡)", total=total)

            with ThreadPoolExecutor(max_workers=PAPER_CONCURRENCY) as pool:
                futs = {pool.submit(_process_paper, pid): pid for pid in target_ids}
                for fut in as_completed(futs):
                    try:
                        fut.result()
                        processed += 1
                        global_tracker.update(task_id, processed, f"æ­£åœ¨å¤„ç†... ({processed}/{total})", total=total)
                    except Exception as exc:
                        failed += 1
                        logger.warning("batch process %s failed: %s", str(futs[fut])[:8], exc)

            global_tracker.finish(task_id, success=True)
            logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {processed} æˆåŠŸ, {failed} å¤±è´¥")
        except Exception as e:
            global_tracker.finish(task_id, success=False, error=str(e))
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}", exc_info=True)

    background_tasks.add_task(_run_batch)
    return {"task_id": task_id, "message": f"æ‰¹é‡å¤„ç†å·²å¯åŠ¨ ({total} ç¯‡è®ºæ–‡)", "status": "running"}


# ---------- è¡ŒåŠ¨è®°å½• ----------


@app.get("/actions")
def list_actions(
    action_type: str | None = None,
    topic_id: str | None = None,
    limit: int = Query(default=50, ge=1, le=200),
    offset: int = Query(default=0, ge=0),
) -> dict:
    """åˆ—å‡ºè®ºæ–‡å…¥åº“è¡ŒåŠ¨è®°å½•"""
    from packages.storage.repositories import ActionRepository
    with session_scope() as session:
        repo = ActionRepository(session)
        actions, total = repo.list_actions(
            action_type=action_type, topic_id=topic_id,
            limit=limit, offset=offset,
        )
        return {
            "items": [
                {
                    "id": a.id,
                    "action_type": a.action_type,
                    "title": a.title,
                    "query": a.query,
                    "topic_id": a.topic_id,
                    "paper_count": a.paper_count,
                    "created_at": a.created_at.isoformat() if a.created_at else None,
                }
                for a in actions
            ],
            "total": total,
        }


@app.get("/actions/{action_id}")
def get_action_detail(action_id: str) -> dict:
    """è·å–è¡ŒåŠ¨è¯¦æƒ…"""
    from packages.storage.repositories import ActionRepository
    with session_scope() as session:
        repo = ActionRepository(session)
        action = repo.get_action(action_id)
        if not action:
            raise HTTPException(status_code=404, detail="è¡ŒåŠ¨è®°å½•ä¸å­˜åœ¨")
        return {
            "id": action.id,
            "action_type": action.action_type,
            "title": action.title,
            "query": action.query,
            "topic_id": action.topic_id,
            "paper_count": action.paper_count,
            "created_at": action.created_at.isoformat() if action.created_at else None,
        }


@app.get("/actions/{action_id}/papers")
def get_action_papers(
    action_id: str,
    limit: int = Query(default=200, ge=1, le=500),
) -> dict:
    """è·å–æŸæ¬¡è¡ŒåŠ¨å…³è”çš„è®ºæ–‡åˆ—è¡¨"""
    from packages.storage.repositories import ActionRepository
    with session_scope() as session:
        repo = ActionRepository(session)
        papers = repo.get_papers_by_action(action_id, limit=limit)
        return {
            "action_id": action_id,
            "items": [
                {
                    "id": p.id,
                    "title": p.title,
                    "arxiv_id": p.arxiv_id,
                    "publication_date": p.publication_date.isoformat() if p.publication_date else None,
                    "read_status": p.read_status,
                }
                for p in papers
            ],
        }


# ---------- æ¨è & è¶‹åŠ¿ ----------


@app.get("/trends/hot")
def hot_keywords(
    days: int = Query(default=7, ge=1, le=30),
    top_k: int = Query(default=15, ge=1, le=50),
) -> dict:
    from packages.ai.recommendation_service import TrendService
    items = TrendService().detect_hot_keywords(days=days, top_k=top_k)
    return {"items": items}


@app.get("/trends/emerging")
def emerging_trends(days: int = Query(default=14, ge=7, le=60)) -> dict:
    from packages.ai.recommendation_service import TrendService
    return TrendService().detect_trends(days=days)


@app.get("/today")
def today_summary() -> dict:
    from packages.ai.recommendation_service import TrendService
    return TrendService().get_today_summary()


# ---------- æŒ‡æ ‡ ----------


@app.get("/metrics/costs")
def cost_metrics(days: int = Query(default=7, ge=1, le=90)) -> dict:
    with session_scope() as session:
        return PromptTraceRepository(session).summarize_costs(days=days)


# ---------- LLM é…ç½®ç®¡ç† ----------


def _mask_key(key: str) -> str:
    """API Key è„±æ•ï¼šåªæ˜¾ç¤ºå‰4å’Œå4"""
    if len(key) <= 12:
        return key[:2] + "****" + key[-2:]
    return key[:4] + "****" + key[-4:]


def _cfg_to_out(cfg) -> dict:
    return {
        "id": cfg.id,
        "name": cfg.name,
        "provider": cfg.provider,
        "api_key_masked": _mask_key(cfg.api_key),
        "api_base_url": cfg.api_base_url,
        "model_skim": cfg.model_skim,
        "model_deep": cfg.model_deep,
        "model_vision": cfg.model_vision,
        "model_embedding": cfg.model_embedding,
        "model_fallback": cfg.model_fallback,
        "is_active": cfg.is_active,
    }


@app.get("/settings/llm-providers")
def list_llm_providers() -> dict:
    with session_scope() as session:
        cfgs = LLMConfigRepository(session).list_all()
        return {"items": [_cfg_to_out(c) for c in cfgs]}


@app.get("/settings/llm-providers/active")
def get_active_llm_config() -> dict:
    """è·å–å½“å‰ç”Ÿæ•ˆçš„ LLM é…ç½®ä¿¡æ¯ï¼ˆå›ºå®šè·¯å¾„ï¼Œå¿…é¡»åœ¨åŠ¨æ€è·¯å¾„ä¹‹å‰ï¼‰"""
    with session_scope() as session:
        active = LLMConfigRepository(session).get_active()
        if active:
            return {
                "source": "database",
                "config": _cfg_to_out(active),
            }
    return {
        "source": "env",
        "config": {
            "provider": settings.llm_provider,
            "model_skim": settings.llm_model_skim,
            "model_deep": settings.llm_model_deep,
            "model_vision": getattr(
                settings, "llm_model_vision", None
            ),
            "model_embedding": settings.embedding_model,
            "model_fallback": settings.llm_model_fallback,
            "is_active": True,
        },
    }


@app.post("/settings/llm-providers/deactivate")
def deactivate_llm_providers() -> dict:
    """å–æ¶ˆæ‰€æœ‰é…ç½®æ¿€æ´»ï¼Œå›é€€åˆ° .env é»˜è®¤é…ç½®"""
    from packages.integrations.llm_client import invalidate_llm_config_cache
    with session_scope() as session:
        LLMConfigRepository(session).deactivate_all()
        invalidate_llm_config_cache()
        return {
            "status": "ok",
            "message": "All deactivated, using .env defaults",
        }


@app.post("/settings/llm-providers")
def create_llm_provider(req: LLMProviderCreate) -> dict:
    with session_scope() as session:
        cfg = LLMConfigRepository(session).create(
            name=req.name,
            provider=req.provider,
            api_key=req.api_key,
            api_base_url=req.api_base_url,
            model_skim=req.model_skim,
            model_deep=req.model_deep,
            model_vision=req.model_vision,
            model_embedding=req.model_embedding,
            model_fallback=req.model_fallback,
        )
        return _cfg_to_out(cfg)


@app.patch("/settings/llm-providers/{config_id}")
def update_llm_provider(
    config_id: str, req: LLMProviderUpdate
) -> dict:
    with session_scope() as session:
        try:
            cfg = LLMConfigRepository(session).update(
                config_id,
                name=req.name,
                provider=req.provider,
                api_key=req.api_key,
                api_base_url=req.api_base_url,
                model_skim=req.model_skim,
                model_deep=req.model_deep,
                model_vision=req.model_vision,
                model_embedding=req.model_embedding,
                model_fallback=req.model_fallback,
            )
        except ValueError as exc:
            raise HTTPException(
                status_code=404, detail=str(exc)
            ) from exc
        return _cfg_to_out(cfg)


@app.delete("/settings/llm-providers/{config_id}")
def delete_llm_provider(config_id: str) -> dict:
    with session_scope() as session:
        LLMConfigRepository(session).delete(config_id)
        return {"deleted": config_id}


@app.post("/settings/llm-providers/{config_id}/activate")
def activate_llm_provider(config_id: str) -> dict:
    from packages.integrations.llm_client import invalidate_llm_config_cache
    with session_scope() as session:
        try:
            cfg = LLMConfigRepository(session).activate(
                config_id
            )
        except ValueError as exc:
            raise HTTPException(
                status_code=404, detail=str(exc)
            ) from exc
        invalidate_llm_config_cache()
        return _cfg_to_out(cfg)


# ---------- å†™ä½œåŠ©æ‰‹ ----------


@app.get("/writing/templates")
def writing_templates() -> dict:
    """è·å–æ‰€æœ‰å†™ä½œæ¨¡æ¿åˆ—è¡¨"""
    from packages.ai.writing_service import WritingService
    return {"items": WritingService.list_templates()}


@app.post("/writing/process")
def writing_process(body: WritingProcessReq) -> dict:
    """æ‰§è¡Œå†™ä½œæ“ä½œ"""
    from packages.ai.writing_service import WritingService
    action = body.action
    text = body.content.strip() or body.topic.strip()
    if not action:
        raise HTTPException(status_code=400, detail="action is required")
    if not text:
        raise HTTPException(status_code=400, detail="text/content is required")
    try:
        return WritingService().process(action, text)
    except ValueError as exc:
        raise HTTPException(400, str(exc)) from exc


@app.post("/writing/refine")
def writing_refine(body: WritingRefineReq) -> dict:
    """åŸºäºå¯¹è¯å†å²å¤šè½®å¾®è°ƒ"""
    from packages.ai.writing_service import WritingService
    messages = body.messages
    if not messages:
        raise HTTPException(status_code=400, detail="messages is required")
    try:
        return WritingService().refine(messages)
    except ValueError as exc:
        raise HTTPException(400, str(exc)) from exc


@app.post("/writing/process-multimodal")
def writing_process_multimodal(body: WritingMultimodalReq) -> dict:
    """å¤šæ¨¡æ€å†™ä½œæ“ä½œï¼ˆå›¾ç‰‡ + æ–‡æœ¬ï¼‰"""
    from packages.ai.writing_service import WritingService
    if not body.image_base64:
        raise HTTPException(status_code=400, detail="image_base64 is required")
    try:
        return WritingService().process_with_image(
            action=body.action,
            text=body.content.strip(),
            image_base64=body.image_base64,
        )
    except ValueError as exc:
        raise HTTPException(400, str(exc)) from exc


# ---------- Agent ----------


_SSE_HEADERS = {
    "Cache-Control": "no-cache, no-store",
    "Connection": "keep-alive",
    "X-Accel-Buffering": "no",
    "X-Content-Type-Options": "nosniff",
}


@app.post("/agent/chat")
async def agent_chat(req: AgentChatRequest):
    """Agent å¯¹è¯ - SSE æµå¼å“åº”"""
    msgs = [m.model_dump() for m in req.messages]
    return StreamingResponse(
        stream_chat(msgs, confirmed_action_id=req.confirmed_action_id),
        media_type="text/event-stream",
        headers=_SSE_HEADERS,
    )


@app.post("/agent/confirm/{action_id}")
async def agent_confirm(action_id: str):
    """ç¡®è®¤æ‰§è¡Œ Agent æŒ‚èµ·çš„æ“ä½œ"""
    return StreamingResponse(
        confirm_action(action_id),
        media_type="text/event-stream",
        headers=_SSE_HEADERS,
    )


@app.post("/agent/reject/{action_id}")
async def agent_reject(action_id: str):
    """æ‹’ç» Agent æŒ‚èµ·çš„æ“ä½œ"""
    return StreamingResponse(
        reject_action(action_id),
        media_type="text/event-stream",
        headers=_SSE_HEADERS,
    )


# ---------- é‚®ç®±é…ç½® ----------


class EmailConfigCreate(BaseModel):
    """åˆ›å»ºé‚®ç®±é…ç½®è¯·æ±‚"""
    name: str
    smtp_server: str
    smtp_port: int = 587
    smtp_use_tls: bool = True
    sender_email: str
    sender_name: str = "PaperMind"
    username: str
    password: str


class EmailConfigUpdate(BaseModel):
    """æ›´æ–°é‚®ç®±é…ç½®è¯·æ±‚"""
    name: str | None = None
    smtp_server: str | None = None
    smtp_port: int | None = None
    smtp_use_tls: bool | None = None
    sender_email: str | None = None
    sender_name: str | None = None
    username: str | None = None
    password: str | None = None


@app.get("/settings/email-configs")
def list_email_configs():
    """è·å–æ‰€æœ‰é‚®ç®±é…ç½®"""
    with session_scope() as session:
        repo = EmailConfigRepository(session)
        configs = repo.list_all()
        return [
            {
                "id": c.id,
                "name": c.name,
                "smtp_server": c.smtp_server,
                "smtp_port": c.smtp_port,
                "smtp_use_tls": c.smtp_use_tls,
                "sender_email": c.sender_email,
                "sender_name": c.sender_name,
                "username": c.username,
                "is_active": c.is_active,
                "created_at": _iso(c.created_at),
            }
            for c in configs
        ]


@app.post("/settings/email-configs")
def create_email_config(body: EmailConfigCreate):
    """åˆ›å»ºé‚®ç®±é…ç½®"""
    with session_scope() as session:
        repo = EmailConfigRepository(session)
        config = repo.create(
            name=body.name,
            smtp_server=body.smtp_server,
            smtp_port=body.smtp_port,
            smtp_use_tls=body.smtp_use_tls,
            sender_email=body.sender_email,
            sender_name=body.sender_name,
            username=body.username,
            password=body.password,
        )
        return {"id": config.id, "message": "é‚®ç®±é…ç½®åˆ›å»ºæˆåŠŸ"}


@app.patch("/settings/email-configs/{config_id}")
def update_email_config(config_id: str, body: EmailConfigUpdate):
    """æ›´æ–°é‚®ç®±é…ç½®"""
    with session_scope() as session:
        repo = EmailConfigRepository(session)
        update_data = {k: v for k, v in body.model_dump().items() if v is not None}
        config = repo.update(config_id, **update_data)
        if not config:
            raise HTTPException(status_code=404, detail="é‚®ç®±é…ç½®ä¸å­˜åœ¨")
        return {"message": "é‚®ç®±é…ç½®æ›´æ–°æˆåŠŸ"}


@app.delete("/settings/email-configs/{config_id}")
def delete_email_config(config_id: str):
    """åˆ é™¤é‚®ç®±é…ç½®"""
    with session_scope() as session:
        repo = EmailConfigRepository(session)
        success = repo.delete(config_id)
        if not success:
            raise HTTPException(status_code=404, detail="é‚®ç®±é…ç½®ä¸å­˜åœ¨")
        return {"message": "é‚®ç®±é…ç½®åˆ é™¤æˆåŠŸ"}


@app.post("/settings/email-configs/{config_id}/activate")
def activate_email_config(config_id: str):
    """æ¿€æ´»é‚®ç®±é…ç½®"""
    with session_scope() as session:
        repo = EmailConfigRepository(session)
        config = repo.set_active(config_id)
        if not config:
            raise HTTPException(status_code=404, detail="é‚®ç®±é…ç½®ä¸å­˜åœ¨")
        return {"message": "é‚®ç®±é…ç½®å·²æ¿€æ´»"}


@app.post("/settings/email-configs/{config_id}/test")
async def test_email_config(config_id: str):
    """æµ‹è¯•é‚®ç®±é…ç½®ï¼ˆå‘é€æµ‹è¯•é‚®ä»¶ï¼‰"""
    from packages.integrations.email_service import create_test_email

    with session_scope() as session:
        repo = EmailConfigRepository(session)
        config = repo.get_by_id(config_id)
        if not config:
            raise HTTPException(status_code=404, detail="é‚®ç®±é…ç½®ä¸å­˜åœ¨")

        # åœ¨sessionå†…å‘é€æµ‹è¯•é‚®ä»¶
        try:
            success = create_test_email(config)
            if success:
                return {"message": "æµ‹è¯•é‚®ä»¶å‘é€æˆåŠŸ"}
            else:
                raise HTTPException(status_code=500, detail="æµ‹è¯•é‚®ä»¶å‘é€å¤±è´¥")
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"æµ‹è¯•é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")


# ---------- æ¯æ—¥æŠ¥å‘Šé…ç½® ----------


class DailyReportConfigUpdate(BaseModel):
    """æ›´æ–°æ¯æ—¥æŠ¥å‘Šé…ç½®è¯·æ±‚"""
    enabled: bool | None = None
    auto_deep_read: bool | None = None
    deep_read_limit: int | None = None
    send_email_report: bool | None = None
    recipient_emails: str | None = None
    report_time_utc: int | None = None
    include_paper_details: bool | None = None
    include_graph_insights: bool | None = None


@app.get("/settings/daily-report-config")
def get_daily_report_config():
    """è·å–æ¯æ—¥æŠ¥å‘Šé…ç½®"""
    from packages.ai.auto_read_service import AutoReadService
    return AutoReadService().get_config()


@app.put("/settings/daily-report-config")
def update_daily_report_config(body: DailyReportConfigUpdate):
    """æ›´æ–°æ¯æ—¥æŠ¥å‘Šé…ç½®"""
    from packages.ai.auto_read_service import AutoReadService
    update_data = {k: v for k, v in body.model_dump().items() if v is not None}
    config = AutoReadService().update_config(**update_data)
    return {"message": "æ¯æ—¥æŠ¥å‘Šé…ç½®å·²æ›´æ–°", "config": config}


@app.post("/jobs/daily-report/run-once")
async def run_daily_report_once(background_tasks: BackgroundTasks):
    """å®Œæ•´å·¥ä½œæµï¼ˆç²¾è¯» + ç”Ÿæˆ + å‘é‚®ä»¶ï¼‰â€” åå°æ‰§è¡Œ"""
    import asyncio
    from packages.ai.auto_read_service import AutoReadService

    def _run_workflow_bg():
        task_id = f"daily_report_{_uuid.uuid4().hex[:8]}"
        global_tracker.start(task_id, "daily_report", "ğŸ“Š æ¯æ—¥æŠ¥å‘Šå·¥ä½œæµ", total=100)

        def _progress(msg: str, cur: int, tot: int):
            global_tracker.update(task_id, cur, msg, total=100)

        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(
                AutoReadService().run_daily_workflow(_progress)
            )
            if result.get("success"):
                global_tracker.finish(task_id, success=True)
            else:
                global_tracker.finish(task_id, success=False, error=result.get("error", "æœªçŸ¥é”™è¯¯"))
        except Exception as e:
            global_tracker.finish(task_id, success=False, error=str(e))
            logger.error(f"æ¯æ—¥æŠ¥å‘Šå·¥ä½œæµå¤±è´¥: {e}", exc_info=True)

    background_tasks.add_task(_run_workflow_bg)
    return {"message": "æ¯æ—¥æŠ¥å‘Šå·¥ä½œæµå·²å¯åŠ¨", "status": "running"}


@app.post("/jobs/daily-report/send-only")
async def run_daily_report_send_only(
    background_tasks: BackgroundTasks,
    recipient: str | None = Query(default=None, description="æ”¶ä»¶äººé‚®ç®±ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä¸å¡«åˆ™ç”¨é…ç½®"),
):
    """å¿«é€Ÿå‘é€æ¨¡å¼ â€” è·³è¿‡ç²¾è¯»ï¼Œç›´æ¥ç”Ÿæˆç®€æŠ¥å¹¶å‘é‚®ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    from packages.ai.auto_read_service import AutoReadService

    def _run_send_only_bg():
        task_id = f"report_send_{_uuid.uuid4().hex[:8]}"
        global_tracker.start(task_id, "report_send", "ğŸ“§ å¿«é€Ÿå‘é€ç®€æŠ¥", total=100)

        def _progress(msg: str, cur: int, tot: int):
            global_tracker.update(task_id, cur, msg, total=100)

        try:
            recipients = [e.strip() for e in recipient.split(",") if e.strip()] if recipient else None
            result = AutoReadService().send_only(recipients, _progress)
            if result.get("success"):
                global_tracker.finish(task_id, success=True)
            else:
                global_tracker.finish(task_id, success=False, error=result.get("error", "æœªçŸ¥é”™è¯¯"))
        except Exception as e:
            global_tracker.finish(task_id, success=False, error=str(e))
            logger.error(f"å¿«é€Ÿå‘é€å¤±è´¥: {e}", exc_info=True)

    background_tasks.add_task(_run_send_only_bg)
    return {"message": "å¿«é€Ÿå‘é€å·²å¯åŠ¨ï¼ˆè·³è¿‡ç²¾è¯»ï¼‰", "status": "running"}


@app.post("/jobs/daily-report/generate-only")
def run_daily_report_generate_only(
    use_cache: bool = Query(default=False, description="æ˜¯å¦ä½¿ç”¨ç¼“å­˜"),
):
    """ä»…ç”Ÿæˆç®€æŠ¥ HTML â€” ä¸å‘é‚®ä»¶ã€ä¸ç²¾è¯»ï¼ˆåŒæ­¥è¿”å›ï¼‰"""
    from packages.ai.auto_read_service import AutoReadService
    html = AutoReadService().step_generate_html(use_cache=use_cache)
    return {"html": html, "used_cache": use_cache}


# ---------- SMTP é…ç½®é¢„è®¾ ----------


@app.get("/settings/smtp-presets")
def get_smtp_presets():
    """è·å–å¸¸è§é‚®ç®±æœåŠ¡å•†çš„ SMTP é…ç½®é¢„è®¾"""
    from packages.integrations.email_service import get_default_smtp_config

    providers = ["gmail", "qq", "163", "outlook"]
    return {provider: get_default_smtp_config(provider) for provider in providers}